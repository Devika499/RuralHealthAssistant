{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12227745,"sourceType":"datasetVersion","datasetId":7704067},{"sourceId":12235629,"sourceType":"datasetVersion","datasetId":7709410}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T08:42:41.473166Z","iopub.execute_input":"2025-06-21T08:42:41.473605Z","iopub.status.idle":"2025-06-21T08:42:41.790068Z","shell.execute_reply.started":"2025-06-21T08:42:41.473586Z","shell.execute_reply":"2025-06-21T08:42:41.789417Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/tinyllama-final/adapter_model.safetensors\n/kaggle/input/tinyllama-final/trainer_state.json\n/kaggle/input/tinyllama-final/training_args.bin\n/kaggle/input/tinyllama-final/adapter_config.json\n/kaggle/input/tinyllama-final/README.md\n/kaggle/input/tinyllama-final/tokenizer.json\n/kaggle/input/tinyllama-final/tokenizer_config.json\n/kaggle/input/tinyllama-final/scaler.pt\n/kaggle/input/tinyllama-final/scheduler.pt\n/kaggle/input/tinyllama-final/special_tokens_map.json\n/kaggle/input/tinyllama-final/optimizer.pt\n/kaggle/input/tinyllama-final/rng_state.pth\n/kaggle/input/tinyllama-final/tokenizer.model\n/kaggle/input/rewardmodel/adapter_model.safetensors\n/kaggle/input/rewardmodel/training_args.bin\n/kaggle/input/rewardmodel/adapter_config.json\n/kaggle/input/rewardmodel/README.md\n/kaggle/input/rewardmodel/tokenizer.json\n/kaggle/input/rewardmodel/tokenizer_config.json\n/kaggle/input/rewardmodel/special_tokens_map.json\n/kaggle/input/rewardmodel/tokenizer.model\n/kaggle/input/reward-model/adapter_model.safetensors\n/kaggle/input/reward-model/training_args.bin\n/kaggle/input/reward-model/adapter_config.json\n/kaggle/input/reward-model/README.md\n/kaggle/input/reward-model/tokenizer.json\n/kaggle/input/reward-model/tokenizer_config.json\n/kaggle/input/reward-model/special_tokens_map.json\n/kaggle/input/reward-model/tokenizer.model\n/kaggle/input/reward-model/checkpoint-1/adapter_model.safetensors\n/kaggle/input/reward-model/checkpoint-1/trainer_state.json\n/kaggle/input/reward-model/checkpoint-1/training_args.bin\n/kaggle/input/reward-model/checkpoint-1/adapter_config.json\n/kaggle/input/reward-model/checkpoint-1/README.md\n/kaggle/input/reward-model/checkpoint-1/tokenizer.json\n/kaggle/input/reward-model/checkpoint-1/tokenizer_config.json\n/kaggle/input/reward-model/checkpoint-1/scaler.pt\n/kaggle/input/reward-model/checkpoint-1/scheduler.pt\n/kaggle/input/reward-model/checkpoint-1/special_tokens_map.json\n/kaggle/input/reward-model/checkpoint-1/optimizer.pt\n/kaggle/input/reward-model/checkpoint-1/rng_state.pth\n/kaggle/input/reward-model/checkpoint-1/tokenizer.model\n/kaggle/input/reward-model/checkpoint-2/adapter_model.safetensors\n/kaggle/input/reward-model/checkpoint-2/trainer_state.json\n/kaggle/input/reward-model/checkpoint-2/training_args.bin\n/kaggle/input/reward-model/checkpoint-2/adapter_config.json\n/kaggle/input/reward-model/checkpoint-2/README.md\n/kaggle/input/reward-model/checkpoint-2/tokenizer.json\n/kaggle/input/reward-model/checkpoint-2/tokenizer_config.json\n/kaggle/input/reward-model/checkpoint-2/scaler.pt\n/kaggle/input/reward-model/checkpoint-2/scheduler.pt\n/kaggle/input/reward-model/checkpoint-2/special_tokens_map.json\n/kaggle/input/reward-model/checkpoint-2/optimizer.pt\n/kaggle/input/reward-model/checkpoint-2/rng_state.pth\n/kaggle/input/reward-model/checkpoint-2/tokenizer.model\n/kaggle/input/reward-model/checkpoint-3/adapter_model.safetensors\n/kaggle/input/reward-model/checkpoint-3/trainer_state.json\n/kaggle/input/reward-model/checkpoint-3/training_args.bin\n/kaggle/input/reward-model/checkpoint-3/adapter_config.json\n/kaggle/input/reward-model/checkpoint-3/README.md\n/kaggle/input/reward-model/checkpoint-3/tokenizer.json\n/kaggle/input/reward-model/checkpoint-3/tokenizer_config.json\n/kaggle/input/reward-model/checkpoint-3/scaler.pt\n/kaggle/input/reward-model/checkpoint-3/scheduler.pt\n/kaggle/input/reward-model/checkpoint-3/special_tokens_map.json\n/kaggle/input/reward-model/checkpoint-3/optimizer.pt\n/kaggle/input/reward-model/checkpoint-3/rng_state.pth\n/kaggle/input/reward-model/checkpoint-3/tokenizer.model\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\nmodel_path = \"/kaggle/input/rewardmodel\"  # path where your trained reward model is saved\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_path,\n    num_labels=3  # âœ… IMPORTANT: Match training setup\n).to(\"cuda\")\n\nmodel.eval()\nprint(\"âœ… Reward model loaded successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T08:45:53.813555Z","iopub.execute_input":"2025-06-21T08:45:53.814316Z","iopub.status.idle":"2025-06-21T08:45:57.398151Z","shell.execute_reply.started":"2025-06-21T08:45:53.814288Z","shell.execute_reply":"2025-06-21T08:45:57.397351Z"}},"outputs":[{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Reward model loaded successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Define Score funtion","metadata":{}},{"cell_type":"code","source":"def score_response(prompt, response):\n    input_text = f\"<|user|>: {prompt} <|assistant|>: {response}\"\n    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=384).to(\"cuda\")\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        score = torch.softmax(outputs.logits, dim=1)[0].tolist()  # probability over rank classes\n\n    return {\n        \"scores\": score,         # e.g., [0.1, 0.3, 0.6] â€” rank 2 most preferred\n        \"predicted_rank\": int(torch.argmax(outputs.logits))  # e.g., 2\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T08:46:04.419405Z","iopub.execute_input":"2025-06-21T08:46:04.420141Z","iopub.status.idle":"2025-06-21T08:46:04.424963Z","shell.execute_reply.started":"2025-06-21T08:46:04.420109Z","shell.execute_reply":"2025-06-21T08:46:04.424133Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Sample responses","metadata":{}},{"cell_type":"code","source":"prompt = \"I have sore throat and fever for 2 days. What could be the cause?\"\n\n# Three generated outputs\nresponse1 = \"You may have a viral infection like the common cold or flu. It's best to stay hydrated and rest.\"\nresponse2 = \"Sore throat and fever may indicate strep throat. Please see a doctor for antibiotics.\"\nresponse3 = \"I think it's just stress. No need to worry about it.\"\n\nprint(\"ðŸ”¹ Response 1:\", score_response(prompt, response1))\nprint(\"ðŸ”¹ Response 2:\", score_response(prompt, response2))\nprint(\"ðŸ”¹ Response 3:\", score_response(prompt, response3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T08:46:08.420564Z","iopub.execute_input":"2025-06-21T08:46:08.421213Z","iopub.status.idle":"2025-06-21T08:46:09.134577Z","shell.execute_reply.started":"2025-06-21T08:46:08.421179Z","shell.execute_reply":"2025-06-21T08:46:09.133755Z"}},"outputs":[{"name":"stdout","text":"ðŸ”¹ Response 1: {'scores': [0.036672789603471756, 0.36894407868385315, 0.594383180141449], 'predicted_rank': 2}\nðŸ”¹ Response 2: {'scores': [0.04787353053689003, 0.0522964708507061, 0.8998300433158875], 'predicted_rank': 2}\nðŸ”¹ Response 3: {'scores': [0.1386435180902481, 0.05790585279464722, 0.8034506440162659], 'predicted_rank': 2}\n","output_type":"stream"}],"execution_count":6}]}
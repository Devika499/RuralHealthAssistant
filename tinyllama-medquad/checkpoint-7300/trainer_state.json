{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9772481040086674,
  "eval_steps": 500,
  "global_step": 7300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0027085590465872156,
      "grad_norm": 74.86450958251953,
      "learning_rate": 4.99796858071506e-05,
      "loss": 5.7548,
      "step": 10
    },
    {
      "epoch": 0.005417118093174431,
      "grad_norm": 22.973600387573242,
      "learning_rate": 4.9911971830985915e-05,
      "loss": 3.5368,
      "step": 20
    },
    {
      "epoch": 0.008125677139761646,
      "grad_norm": 16.31926918029785,
      "learning_rate": 4.9844257854821234e-05,
      "loss": 1.5998,
      "step": 30
    },
    {
      "epoch": 0.010834236186348862,
      "grad_norm": 1.0073708295822144,
      "learning_rate": 4.9776543878656554e-05,
      "loss": 1.0434,
      "step": 40
    },
    {
      "epoch": 0.013542795232936078,
      "grad_norm": 0.9312379360198975,
      "learning_rate": 4.9708829902491874e-05,
      "loss": 0.9339,
      "step": 50
    },
    {
      "epoch": 0.016251354279523293,
      "grad_norm": 0.6936874389648438,
      "learning_rate": 4.96411159263272e-05,
      "loss": 1.0355,
      "step": 60
    },
    {
      "epoch": 0.01895991332611051,
      "grad_norm": 0.6859848499298096,
      "learning_rate": 4.957340195016252e-05,
      "loss": 0.9563,
      "step": 70
    },
    {
      "epoch": 0.021668472372697724,
      "grad_norm": 0.6153332591056824,
      "learning_rate": 4.950568797399783e-05,
      "loss": 0.8822,
      "step": 80
    },
    {
      "epoch": 0.02437703141928494,
      "grad_norm": 0.8599089980125427,
      "learning_rate": 4.943797399783315e-05,
      "loss": 0.9255,
      "step": 90
    },
    {
      "epoch": 0.027085590465872156,
      "grad_norm": 1.0647274255752563,
      "learning_rate": 4.937026002166847e-05,
      "loss": 0.7664,
      "step": 100
    },
    {
      "epoch": 0.029794149512459372,
      "grad_norm": 0.8385348320007324,
      "learning_rate": 4.930254604550379e-05,
      "loss": 0.8479,
      "step": 110
    },
    {
      "epoch": 0.032502708559046585,
      "grad_norm": 1.0118006467819214,
      "learning_rate": 4.923483206933911e-05,
      "loss": 0.8709,
      "step": 120
    },
    {
      "epoch": 0.035211267605633804,
      "grad_norm": 0.970607578754425,
      "learning_rate": 4.916711809317444e-05,
      "loss": 0.8823,
      "step": 130
    },
    {
      "epoch": 0.03791982665222102,
      "grad_norm": 0.8655775189399719,
      "learning_rate": 4.909940411700975e-05,
      "loss": 0.7378,
      "step": 140
    },
    {
      "epoch": 0.040628385698808236,
      "grad_norm": 1.0402709245681763,
      "learning_rate": 4.903169014084507e-05,
      "loss": 0.8278,
      "step": 150
    },
    {
      "epoch": 0.04333694474539545,
      "grad_norm": 0.9047091603279114,
      "learning_rate": 4.896397616468039e-05,
      "loss": 0.6989,
      "step": 160
    },
    {
      "epoch": 0.04604550379198267,
      "grad_norm": 0.8692451119422913,
      "learning_rate": 4.889626218851571e-05,
      "loss": 0.7983,
      "step": 170
    },
    {
      "epoch": 0.04875406283856988,
      "grad_norm": 1.230677843093872,
      "learning_rate": 4.882854821235103e-05,
      "loss": 0.8292,
      "step": 180
    },
    {
      "epoch": 0.051462621885157094,
      "grad_norm": 1.0325722694396973,
      "learning_rate": 4.876083423618635e-05,
      "loss": 0.795,
      "step": 190
    },
    {
      "epoch": 0.05417118093174431,
      "grad_norm": 1.0644174814224243,
      "learning_rate": 4.869312026002167e-05,
      "loss": 0.7035,
      "step": 200
    },
    {
      "epoch": 0.056879739978331526,
      "grad_norm": 1.639565110206604,
      "learning_rate": 4.862540628385699e-05,
      "loss": 0.8436,
      "step": 210
    },
    {
      "epoch": 0.059588299024918745,
      "grad_norm": 1.029076337814331,
      "learning_rate": 4.855769230769231e-05,
      "loss": 0.708,
      "step": 220
    },
    {
      "epoch": 0.06229685807150596,
      "grad_norm": 1.4917893409729004,
      "learning_rate": 4.848997833152763e-05,
      "loss": 0.7223,
      "step": 230
    },
    {
      "epoch": 0.06500541711809317,
      "grad_norm": 1.2493977546691895,
      "learning_rate": 4.842226435536295e-05,
      "loss": 0.7422,
      "step": 240
    },
    {
      "epoch": 0.06771397616468039,
      "grad_norm": 1.1127243041992188,
      "learning_rate": 4.835455037919827e-05,
      "loss": 0.8266,
      "step": 250
    },
    {
      "epoch": 0.07042253521126761,
      "grad_norm": 1.007204532623291,
      "learning_rate": 4.828683640303359e-05,
      "loss": 0.7435,
      "step": 260
    },
    {
      "epoch": 0.07313109425785481,
      "grad_norm": 1.1278287172317505,
      "learning_rate": 4.821912242686891e-05,
      "loss": 0.7148,
      "step": 270
    },
    {
      "epoch": 0.07583965330444203,
      "grad_norm": 1.243213415145874,
      "learning_rate": 4.815140845070423e-05,
      "loss": 0.7974,
      "step": 280
    },
    {
      "epoch": 0.07854821235102925,
      "grad_norm": 1.2567569017410278,
      "learning_rate": 4.808369447453955e-05,
      "loss": 0.6343,
      "step": 290
    },
    {
      "epoch": 0.08125677139761647,
      "grad_norm": 1.1099399328231812,
      "learning_rate": 4.801598049837487e-05,
      "loss": 0.7008,
      "step": 300
    },
    {
      "epoch": 0.08396533044420368,
      "grad_norm": 1.2720613479614258,
      "learning_rate": 4.794826652221019e-05,
      "loss": 0.7806,
      "step": 310
    },
    {
      "epoch": 0.0866738894907909,
      "grad_norm": 1.9052602052688599,
      "learning_rate": 4.78805525460455e-05,
      "loss": 0.6854,
      "step": 320
    },
    {
      "epoch": 0.08938244853737812,
      "grad_norm": 1.4528626203536987,
      "learning_rate": 4.781283856988083e-05,
      "loss": 0.6982,
      "step": 330
    },
    {
      "epoch": 0.09209100758396534,
      "grad_norm": 1.3796852827072144,
      "learning_rate": 4.774512459371615e-05,
      "loss": 0.4919,
      "step": 340
    },
    {
      "epoch": 0.09479956663055254,
      "grad_norm": 1.2786784172058105,
      "learning_rate": 4.767741061755147e-05,
      "loss": 0.7238,
      "step": 350
    },
    {
      "epoch": 0.09750812567713976,
      "grad_norm": 1.0340323448181152,
      "learning_rate": 4.760969664138679e-05,
      "loss": 0.6534,
      "step": 360
    },
    {
      "epoch": 0.10021668472372698,
      "grad_norm": 1.1917394399642944,
      "learning_rate": 4.7541982665222106e-05,
      "loss": 0.6816,
      "step": 370
    },
    {
      "epoch": 0.10292524377031419,
      "grad_norm": 1.3741105794906616,
      "learning_rate": 4.747426868905742e-05,
      "loss": 0.675,
      "step": 380
    },
    {
      "epoch": 0.1056338028169014,
      "grad_norm": 1.0655752420425415,
      "learning_rate": 4.740655471289274e-05,
      "loss": 0.5632,
      "step": 390
    },
    {
      "epoch": 0.10834236186348863,
      "grad_norm": 1.0658396482467651,
      "learning_rate": 4.7338840736728066e-05,
      "loss": 0.6038,
      "step": 400
    },
    {
      "epoch": 0.11105092091007585,
      "grad_norm": 1.1291016340255737,
      "learning_rate": 4.7271126760563385e-05,
      "loss": 0.6902,
      "step": 410
    },
    {
      "epoch": 0.11375947995666305,
      "grad_norm": 1.1507365703582764,
      "learning_rate": 4.7203412784398705e-05,
      "loss": 0.6429,
      "step": 420
    },
    {
      "epoch": 0.11646803900325027,
      "grad_norm": 0.98618084192276,
      "learning_rate": 4.7135698808234025e-05,
      "loss": 0.7288,
      "step": 430
    },
    {
      "epoch": 0.11917659804983749,
      "grad_norm": 0.9022283554077148,
      "learning_rate": 4.706798483206934e-05,
      "loss": 0.5839,
      "step": 440
    },
    {
      "epoch": 0.1218851570964247,
      "grad_norm": 0.9150943756103516,
      "learning_rate": 4.700027085590466e-05,
      "loss": 0.6971,
      "step": 450
    },
    {
      "epoch": 0.12459371614301191,
      "grad_norm": 1.44197416305542,
      "learning_rate": 4.693255687973998e-05,
      "loss": 0.6363,
      "step": 460
    },
    {
      "epoch": 0.12730227518959913,
      "grad_norm": 1.6324334144592285,
      "learning_rate": 4.6864842903575304e-05,
      "loss": 0.6061,
      "step": 470
    },
    {
      "epoch": 0.13001083423618634,
      "grad_norm": 0.9872215390205383,
      "learning_rate": 4.6797128927410624e-05,
      "loss": 0.7567,
      "step": 480
    },
    {
      "epoch": 0.13271939328277357,
      "grad_norm": 1.166359543800354,
      "learning_rate": 4.672941495124594e-05,
      "loss": 0.7987,
      "step": 490
    },
    {
      "epoch": 0.13542795232936078,
      "grad_norm": 1.3301010131835938,
      "learning_rate": 4.6661700975081257e-05,
      "loss": 0.7453,
      "step": 500
    },
    {
      "epoch": 0.13813651137594798,
      "grad_norm": 1.0710595846176147,
      "learning_rate": 4.6593986998916576e-05,
      "loss": 0.7962,
      "step": 510
    },
    {
      "epoch": 0.14084507042253522,
      "grad_norm": 1.0789743661880493,
      "learning_rate": 4.6526273022751896e-05,
      "loss": 0.6646,
      "step": 520
    },
    {
      "epoch": 0.14355362946912242,
      "grad_norm": 1.1662100553512573,
      "learning_rate": 4.6458559046587216e-05,
      "loss": 0.5145,
      "step": 530
    },
    {
      "epoch": 0.14626218851570963,
      "grad_norm": 1.2659910917282104,
      "learning_rate": 4.639084507042254e-05,
      "loss": 0.6943,
      "step": 540
    },
    {
      "epoch": 0.14897074756229686,
      "grad_norm": 0.9836048483848572,
      "learning_rate": 4.6323131094257855e-05,
      "loss": 0.6596,
      "step": 550
    },
    {
      "epoch": 0.15167930660888407,
      "grad_norm": 1.0488229990005493,
      "learning_rate": 4.6255417118093175e-05,
      "loss": 0.6838,
      "step": 560
    },
    {
      "epoch": 0.1543878656554713,
      "grad_norm": 1.0399744510650635,
      "learning_rate": 4.6187703141928495e-05,
      "loss": 0.6591,
      "step": 570
    },
    {
      "epoch": 0.1570964247020585,
      "grad_norm": 1.3451560735702515,
      "learning_rate": 4.6119989165763815e-05,
      "loss": 0.6767,
      "step": 580
    },
    {
      "epoch": 0.1598049837486457,
      "grad_norm": 1.1236969232559204,
      "learning_rate": 4.6052275189599134e-05,
      "loss": 0.6189,
      "step": 590
    },
    {
      "epoch": 0.16251354279523295,
      "grad_norm": 0.753260612487793,
      "learning_rate": 4.5984561213434454e-05,
      "loss": 0.5349,
      "step": 600
    },
    {
      "epoch": 0.16522210184182015,
      "grad_norm": 1.1170501708984375,
      "learning_rate": 4.5916847237269774e-05,
      "loss": 0.5354,
      "step": 610
    },
    {
      "epoch": 0.16793066088840736,
      "grad_norm": 0.9628806114196777,
      "learning_rate": 4.5849133261105094e-05,
      "loss": 0.7328,
      "step": 620
    },
    {
      "epoch": 0.1706392199349946,
      "grad_norm": 0.9888660907745361,
      "learning_rate": 4.5781419284940413e-05,
      "loss": 0.5222,
      "step": 630
    },
    {
      "epoch": 0.1733477789815818,
      "grad_norm": 0.8614304065704346,
      "learning_rate": 4.571370530877573e-05,
      "loss": 0.7057,
      "step": 640
    },
    {
      "epoch": 0.176056338028169,
      "grad_norm": 0.8480393290519714,
      "learning_rate": 4.564599133261105e-05,
      "loss": 0.5295,
      "step": 650
    },
    {
      "epoch": 0.17876489707475623,
      "grad_norm": 1.07114839553833,
      "learning_rate": 4.557827735644637e-05,
      "loss": 0.7873,
      "step": 660
    },
    {
      "epoch": 0.18147345612134344,
      "grad_norm": 1.0345462560653687,
      "learning_rate": 4.551056338028169e-05,
      "loss": 0.606,
      "step": 670
    },
    {
      "epoch": 0.18418201516793067,
      "grad_norm": 1.017933964729309,
      "learning_rate": 4.544284940411701e-05,
      "loss": 0.6106,
      "step": 680
    },
    {
      "epoch": 0.18689057421451788,
      "grad_norm": 0.9178757667541504,
      "learning_rate": 4.537513542795233e-05,
      "loss": 0.5305,
      "step": 690
    },
    {
      "epoch": 0.18959913326110509,
      "grad_norm": 0.9879750609397888,
      "learning_rate": 4.530742145178765e-05,
      "loss": 0.7336,
      "step": 700
    },
    {
      "epoch": 0.19230769230769232,
      "grad_norm": 0.9050801396369934,
      "learning_rate": 4.523970747562297e-05,
      "loss": 0.6822,
      "step": 710
    },
    {
      "epoch": 0.19501625135427952,
      "grad_norm": 1.2804876565933228,
      "learning_rate": 4.517199349945829e-05,
      "loss": 0.6687,
      "step": 720
    },
    {
      "epoch": 0.19772481040086673,
      "grad_norm": 1.1140599250793457,
      "learning_rate": 4.510427952329361e-05,
      "loss": 0.6095,
      "step": 730
    },
    {
      "epoch": 0.20043336944745396,
      "grad_norm": 0.9889272451400757,
      "learning_rate": 4.503656554712893e-05,
      "loss": 0.6351,
      "step": 740
    },
    {
      "epoch": 0.20314192849404117,
      "grad_norm": 1.0213881731033325,
      "learning_rate": 4.496885157096425e-05,
      "loss": 0.5694,
      "step": 750
    },
    {
      "epoch": 0.20585048754062837,
      "grad_norm": 1.0641015768051147,
      "learning_rate": 4.490113759479957e-05,
      "loss": 0.7637,
      "step": 760
    },
    {
      "epoch": 0.2085590465872156,
      "grad_norm": 0.8432797193527222,
      "learning_rate": 4.483342361863489e-05,
      "loss": 0.7624,
      "step": 770
    },
    {
      "epoch": 0.2112676056338028,
      "grad_norm": 0.7181774973869324,
      "learning_rate": 4.476570964247021e-05,
      "loss": 0.6668,
      "step": 780
    },
    {
      "epoch": 0.21397616468039005,
      "grad_norm": 0.8694762587547302,
      "learning_rate": 4.469799566630552e-05,
      "loss": 0.5954,
      "step": 790
    },
    {
      "epoch": 0.21668472372697725,
      "grad_norm": 1.0743184089660645,
      "learning_rate": 4.463028169014085e-05,
      "loss": 0.6701,
      "step": 800
    },
    {
      "epoch": 0.21939328277356446,
      "grad_norm": 1.0831828117370605,
      "learning_rate": 4.456256771397617e-05,
      "loss": 0.7517,
      "step": 810
    },
    {
      "epoch": 0.2221018418201517,
      "grad_norm": 0.8618528246879578,
      "learning_rate": 4.449485373781149e-05,
      "loss": 0.6056,
      "step": 820
    },
    {
      "epoch": 0.2248104008667389,
      "grad_norm": 1.090995192527771,
      "learning_rate": 4.442713976164681e-05,
      "loss": 0.6264,
      "step": 830
    },
    {
      "epoch": 0.2275189599133261,
      "grad_norm": 1.0727765560150146,
      "learning_rate": 4.435942578548213e-05,
      "loss": 0.5936,
      "step": 840
    },
    {
      "epoch": 0.23022751895991334,
      "grad_norm": 0.9332026243209839,
      "learning_rate": 4.429171180931744e-05,
      "loss": 0.6481,
      "step": 850
    },
    {
      "epoch": 0.23293607800650054,
      "grad_norm": 1.0461100339889526,
      "learning_rate": 4.422399783315276e-05,
      "loss": 0.7361,
      "step": 860
    },
    {
      "epoch": 0.23564463705308775,
      "grad_norm": 1.5904935598373413,
      "learning_rate": 4.415628385698808e-05,
      "loss": 0.7097,
      "step": 870
    },
    {
      "epoch": 0.23835319609967498,
      "grad_norm": 1.5621392726898193,
      "learning_rate": 4.408856988082341e-05,
      "loss": 0.6161,
      "step": 880
    },
    {
      "epoch": 0.24106175514626219,
      "grad_norm": 1.1315754652023315,
      "learning_rate": 4.402085590465873e-05,
      "loss": 0.6773,
      "step": 890
    },
    {
      "epoch": 0.2437703141928494,
      "grad_norm": 0.9381213784217834,
      "learning_rate": 4.395314192849405e-05,
      "loss": 0.6885,
      "step": 900
    },
    {
      "epoch": 0.24647887323943662,
      "grad_norm": 1.1272318363189697,
      "learning_rate": 4.388542795232936e-05,
      "loss": 0.5629,
      "step": 910
    },
    {
      "epoch": 0.24918743228602383,
      "grad_norm": 1.2754703760147095,
      "learning_rate": 4.381771397616468e-05,
      "loss": 0.5366,
      "step": 920
    },
    {
      "epoch": 0.25189599133261104,
      "grad_norm": 0.9411577582359314,
      "learning_rate": 4.375e-05,
      "loss": 0.7049,
      "step": 930
    },
    {
      "epoch": 0.25460455037919827,
      "grad_norm": 1.1014090776443481,
      "learning_rate": 4.368228602383532e-05,
      "loss": 0.7079,
      "step": 940
    },
    {
      "epoch": 0.2573131094257855,
      "grad_norm": 0.989240825176239,
      "learning_rate": 4.3614572047670646e-05,
      "loss": 0.723,
      "step": 950
    },
    {
      "epoch": 0.2600216684723727,
      "grad_norm": 1.2473926544189453,
      "learning_rate": 4.354685807150596e-05,
      "loss": 0.6101,
      "step": 960
    },
    {
      "epoch": 0.2627302275189599,
      "grad_norm": 0.950141429901123,
      "learning_rate": 4.347914409534128e-05,
      "loss": 0.7197,
      "step": 970
    },
    {
      "epoch": 0.26543878656554715,
      "grad_norm": 1.2524700164794922,
      "learning_rate": 4.34114301191766e-05,
      "loss": 0.5902,
      "step": 980
    },
    {
      "epoch": 0.2681473456121343,
      "grad_norm": 1.2759228944778442,
      "learning_rate": 4.334371614301192e-05,
      "loss": 0.8071,
      "step": 990
    },
    {
      "epoch": 0.27085590465872156,
      "grad_norm": 1.3685832023620605,
      "learning_rate": 4.327600216684724e-05,
      "loss": 0.6386,
      "step": 1000
    },
    {
      "epoch": 0.2735644637053088,
      "grad_norm": 2.218273639678955,
      "learning_rate": 4.320828819068256e-05,
      "loss": 0.744,
      "step": 1010
    },
    {
      "epoch": 0.27627302275189597,
      "grad_norm": 1.062643051147461,
      "learning_rate": 4.314057421451788e-05,
      "loss": 0.7762,
      "step": 1020
    },
    {
      "epoch": 0.2789815817984832,
      "grad_norm": 0.9227453470230103,
      "learning_rate": 4.30728602383532e-05,
      "loss": 0.5774,
      "step": 1030
    },
    {
      "epoch": 0.28169014084507044,
      "grad_norm": 1.0537083148956299,
      "learning_rate": 4.300514626218852e-05,
      "loss": 0.7022,
      "step": 1040
    },
    {
      "epoch": 0.2843986998916576,
      "grad_norm": 1.0254247188568115,
      "learning_rate": 4.293743228602384e-05,
      "loss": 0.6238,
      "step": 1050
    },
    {
      "epoch": 0.28710725893824485,
      "grad_norm": 1.0230647325515747,
      "learning_rate": 4.2869718309859156e-05,
      "loss": 0.5962,
      "step": 1060
    },
    {
      "epoch": 0.2898158179848321,
      "grad_norm": 1.1682069301605225,
      "learning_rate": 4.2802004333694476e-05,
      "loss": 0.6502,
      "step": 1070
    },
    {
      "epoch": 0.29252437703141926,
      "grad_norm": 1.1128562688827515,
      "learning_rate": 4.2734290357529796e-05,
      "loss": 0.5642,
      "step": 1080
    },
    {
      "epoch": 0.2952329360780065,
      "grad_norm": 0.872637927532196,
      "learning_rate": 4.2666576381365116e-05,
      "loss": 0.6632,
      "step": 1090
    },
    {
      "epoch": 0.2979414951245937,
      "grad_norm": 0.8375647664070129,
      "learning_rate": 4.2598862405200436e-05,
      "loss": 0.6554,
      "step": 1100
    },
    {
      "epoch": 0.30065005417118096,
      "grad_norm": 1.1819825172424316,
      "learning_rate": 4.2531148429035755e-05,
      "loss": 0.5407,
      "step": 1110
    },
    {
      "epoch": 0.30335861321776814,
      "grad_norm": 1.3440309762954712,
      "learning_rate": 4.2463434452871075e-05,
      "loss": 0.7467,
      "step": 1120
    },
    {
      "epoch": 0.30606717226435537,
      "grad_norm": 1.2361140251159668,
      "learning_rate": 4.2395720476706395e-05,
      "loss": 0.6489,
      "step": 1130
    },
    {
      "epoch": 0.3087757313109426,
      "grad_norm": 0.9721911549568176,
      "learning_rate": 4.2328006500541715e-05,
      "loss": 0.6373,
      "step": 1140
    },
    {
      "epoch": 0.3114842903575298,
      "grad_norm": 1.4211398363113403,
      "learning_rate": 4.2260292524377034e-05,
      "loss": 0.7234,
      "step": 1150
    },
    {
      "epoch": 0.314192849404117,
      "grad_norm": 1.0577524900436401,
      "learning_rate": 4.2192578548212354e-05,
      "loss": 0.6248,
      "step": 1160
    },
    {
      "epoch": 0.31690140845070425,
      "grad_norm": 1.0463480949401855,
      "learning_rate": 4.2124864572047674e-05,
      "loss": 0.7461,
      "step": 1170
    },
    {
      "epoch": 0.3196099674972914,
      "grad_norm": 1.4424569606781006,
      "learning_rate": 4.2057150595882994e-05,
      "loss": 0.563,
      "step": 1180
    },
    {
      "epoch": 0.32231852654387866,
      "grad_norm": 1.447982668876648,
      "learning_rate": 4.198943661971831e-05,
      "loss": 0.6896,
      "step": 1190
    },
    {
      "epoch": 0.3250270855904659,
      "grad_norm": 1.0611522197723389,
      "learning_rate": 4.1921722643553626e-05,
      "loss": 0.7407,
      "step": 1200
    },
    {
      "epoch": 0.32773564463705307,
      "grad_norm": 1.4228423833847046,
      "learning_rate": 4.185400866738895e-05,
      "loss": 0.653,
      "step": 1210
    },
    {
      "epoch": 0.3304442036836403,
      "grad_norm": 1.0796477794647217,
      "learning_rate": 4.178629469122427e-05,
      "loss": 0.5993,
      "step": 1220
    },
    {
      "epoch": 0.33315276273022754,
      "grad_norm": 1.2232518196105957,
      "learning_rate": 4.171858071505959e-05,
      "loss": 0.6333,
      "step": 1230
    },
    {
      "epoch": 0.3358613217768147,
      "grad_norm": 0.9794799089431763,
      "learning_rate": 4.165086673889491e-05,
      "loss": 0.6914,
      "step": 1240
    },
    {
      "epoch": 0.33856988082340195,
      "grad_norm": 1.1907252073287964,
      "learning_rate": 4.158315276273023e-05,
      "loss": 0.6876,
      "step": 1250
    },
    {
      "epoch": 0.3412784398699892,
      "grad_norm": 0.9789705276489258,
      "learning_rate": 4.1515438786565545e-05,
      "loss": 0.6043,
      "step": 1260
    },
    {
      "epoch": 0.34398699891657636,
      "grad_norm": 0.9507989883422852,
      "learning_rate": 4.1447724810400865e-05,
      "loss": 0.7078,
      "step": 1270
    },
    {
      "epoch": 0.3466955579631636,
      "grad_norm": 0.8088932037353516,
      "learning_rate": 4.138001083423619e-05,
      "loss": 0.623,
      "step": 1280
    },
    {
      "epoch": 0.3494041170097508,
      "grad_norm": 1.0791667699813843,
      "learning_rate": 4.131229685807151e-05,
      "loss": 0.6624,
      "step": 1290
    },
    {
      "epoch": 0.352112676056338,
      "grad_norm": 1.7721302509307861,
      "learning_rate": 4.124458288190683e-05,
      "loss": 0.6688,
      "step": 1300
    },
    {
      "epoch": 0.35482123510292524,
      "grad_norm": 0.9923955202102661,
      "learning_rate": 4.117686890574215e-05,
      "loss": 0.6506,
      "step": 1310
    },
    {
      "epoch": 0.35752979414951247,
      "grad_norm": 1.258339285850525,
      "learning_rate": 4.1109154929577464e-05,
      "loss": 0.6705,
      "step": 1320
    },
    {
      "epoch": 0.36023835319609965,
      "grad_norm": 1.8881280422210693,
      "learning_rate": 4.104144095341278e-05,
      "loss": 0.7464,
      "step": 1330
    },
    {
      "epoch": 0.3629469122426869,
      "grad_norm": 1.2181662321090698,
      "learning_rate": 4.09737269772481e-05,
      "loss": 0.7053,
      "step": 1340
    },
    {
      "epoch": 0.3656554712892741,
      "grad_norm": 1.0715621709823608,
      "learning_rate": 4.090601300108343e-05,
      "loss": 0.6722,
      "step": 1350
    },
    {
      "epoch": 0.36836403033586135,
      "grad_norm": 1.14789617061615,
      "learning_rate": 4.083829902491875e-05,
      "loss": 0.6526,
      "step": 1360
    },
    {
      "epoch": 0.3710725893824485,
      "grad_norm": 1.3321512937545776,
      "learning_rate": 4.077058504875407e-05,
      "loss": 0.7004,
      "step": 1370
    },
    {
      "epoch": 0.37378114842903576,
      "grad_norm": 0.7595576047897339,
      "learning_rate": 4.070287107258938e-05,
      "loss": 0.592,
      "step": 1380
    },
    {
      "epoch": 0.376489707475623,
      "grad_norm": 1.111132264137268,
      "learning_rate": 4.06351570964247e-05,
      "loss": 0.7318,
      "step": 1390
    },
    {
      "epoch": 0.37919826652221017,
      "grad_norm": 0.9961467385292053,
      "learning_rate": 4.056744312026002e-05,
      "loss": 0.6619,
      "step": 1400
    },
    {
      "epoch": 0.3819068255687974,
      "grad_norm": 0.990979015827179,
      "learning_rate": 4.049972914409534e-05,
      "loss": 0.6276,
      "step": 1410
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 1.1582145690917969,
      "learning_rate": 4.043201516793067e-05,
      "loss": 0.6269,
      "step": 1420
    },
    {
      "epoch": 0.3873239436619718,
      "grad_norm": 1.1223233938217163,
      "learning_rate": 4.036430119176598e-05,
      "loss": 0.6186,
      "step": 1430
    },
    {
      "epoch": 0.39003250270855905,
      "grad_norm": 1.1944974660873413,
      "learning_rate": 4.02965872156013e-05,
      "loss": 0.6594,
      "step": 1440
    },
    {
      "epoch": 0.3927410617551463,
      "grad_norm": 0.9685338735580444,
      "learning_rate": 4.022887323943662e-05,
      "loss": 0.5681,
      "step": 1450
    },
    {
      "epoch": 0.39544962080173346,
      "grad_norm": 1.2467634677886963,
      "learning_rate": 4.016115926327194e-05,
      "loss": 0.7531,
      "step": 1460
    },
    {
      "epoch": 0.3981581798483207,
      "grad_norm": 0.7870612144470215,
      "learning_rate": 4.009344528710726e-05,
      "loss": 0.6808,
      "step": 1470
    },
    {
      "epoch": 0.4008667388949079,
      "grad_norm": 1.0698909759521484,
      "learning_rate": 4.002573131094258e-05,
      "loss": 0.5603,
      "step": 1480
    },
    {
      "epoch": 0.4035752979414951,
      "grad_norm": 1.027994155883789,
      "learning_rate": 3.99580173347779e-05,
      "loss": 0.5141,
      "step": 1490
    },
    {
      "epoch": 0.40628385698808234,
      "grad_norm": 0.9232099652290344,
      "learning_rate": 3.989030335861322e-05,
      "loss": 0.6276,
      "step": 1500
    },
    {
      "epoch": 0.40899241603466957,
      "grad_norm": 0.9511818885803223,
      "learning_rate": 3.982258938244854e-05,
      "loss": 0.6936,
      "step": 1510
    },
    {
      "epoch": 0.41170097508125675,
      "grad_norm": 1.086859107017517,
      "learning_rate": 3.975487540628386e-05,
      "loss": 0.599,
      "step": 1520
    },
    {
      "epoch": 0.414409534127844,
      "grad_norm": 1.2143422365188599,
      "learning_rate": 3.968716143011918e-05,
      "loss": 0.6173,
      "step": 1530
    },
    {
      "epoch": 0.4171180931744312,
      "grad_norm": 1.1162385940551758,
      "learning_rate": 3.96194474539545e-05,
      "loss": 0.6733,
      "step": 1540
    },
    {
      "epoch": 0.4198266522210184,
      "grad_norm": 0.7999485731124878,
      "learning_rate": 3.955173347778982e-05,
      "loss": 0.6612,
      "step": 1550
    },
    {
      "epoch": 0.4225352112676056,
      "grad_norm": 1.1621220111846924,
      "learning_rate": 3.948401950162514e-05,
      "loss": 0.5509,
      "step": 1560
    },
    {
      "epoch": 0.42524377031419286,
      "grad_norm": 1.1755036115646362,
      "learning_rate": 3.941630552546046e-05,
      "loss": 0.7406,
      "step": 1570
    },
    {
      "epoch": 0.4279523293607801,
      "grad_norm": 1.2470293045043945,
      "learning_rate": 3.934859154929578e-05,
      "loss": 0.7,
      "step": 1580
    },
    {
      "epoch": 0.43066088840736727,
      "grad_norm": 0.9075801372528076,
      "learning_rate": 3.92808775731311e-05,
      "loss": 0.6085,
      "step": 1590
    },
    {
      "epoch": 0.4333694474539545,
      "grad_norm": 1.25168776512146,
      "learning_rate": 3.921316359696642e-05,
      "loss": 0.7346,
      "step": 1600
    },
    {
      "epoch": 0.43607800650054174,
      "grad_norm": 1.1318539381027222,
      "learning_rate": 3.914544962080173e-05,
      "loss": 0.6892,
      "step": 1610
    },
    {
      "epoch": 0.4387865655471289,
      "grad_norm": 1.070508599281311,
      "learning_rate": 3.9077735644637056e-05,
      "loss": 0.7323,
      "step": 1620
    },
    {
      "epoch": 0.44149512459371615,
      "grad_norm": 1.5369372367858887,
      "learning_rate": 3.9010021668472376e-05,
      "loss": 0.7086,
      "step": 1630
    },
    {
      "epoch": 0.4442036836403034,
      "grad_norm": 0.9270630478858948,
      "learning_rate": 3.8942307692307696e-05,
      "loss": 0.6914,
      "step": 1640
    },
    {
      "epoch": 0.44691224268689056,
      "grad_norm": 1.3397067785263062,
      "learning_rate": 3.8874593716143016e-05,
      "loss": 0.6587,
      "step": 1650
    },
    {
      "epoch": 0.4496208017334778,
      "grad_norm": 1.1774301528930664,
      "learning_rate": 3.8806879739978335e-05,
      "loss": 0.6501,
      "step": 1660
    },
    {
      "epoch": 0.452329360780065,
      "grad_norm": 1.1160694360733032,
      "learning_rate": 3.873916576381365e-05,
      "loss": 0.5466,
      "step": 1670
    },
    {
      "epoch": 0.4550379198266522,
      "grad_norm": 0.9795174598693848,
      "learning_rate": 3.867145178764897e-05,
      "loss": 0.6694,
      "step": 1680
    },
    {
      "epoch": 0.45774647887323944,
      "grad_norm": 1.3575477600097656,
      "learning_rate": 3.8603737811484295e-05,
      "loss": 0.4773,
      "step": 1690
    },
    {
      "epoch": 0.46045503791982667,
      "grad_norm": 1.278027892112732,
      "learning_rate": 3.8536023835319615e-05,
      "loss": 0.6861,
      "step": 1700
    },
    {
      "epoch": 0.46316359696641385,
      "grad_norm": 0.9241560101509094,
      "learning_rate": 3.8468309859154934e-05,
      "loss": 0.5505,
      "step": 1710
    },
    {
      "epoch": 0.4658721560130011,
      "grad_norm": 1.0509074926376343,
      "learning_rate": 3.8400595882990254e-05,
      "loss": 0.646,
      "step": 1720
    },
    {
      "epoch": 0.4685807150595883,
      "grad_norm": 1.1870722770690918,
      "learning_rate": 3.833288190682557e-05,
      "loss": 0.7272,
      "step": 1730
    },
    {
      "epoch": 0.4712892741061755,
      "grad_norm": 0.9966045618057251,
      "learning_rate": 3.826516793066089e-05,
      "loss": 0.6359,
      "step": 1740
    },
    {
      "epoch": 0.4739978331527627,
      "grad_norm": 0.7433739304542542,
      "learning_rate": 3.8197453954496207e-05,
      "loss": 0.4516,
      "step": 1750
    },
    {
      "epoch": 0.47670639219934996,
      "grad_norm": 0.995786190032959,
      "learning_rate": 3.812973997833153e-05,
      "loss": 0.6467,
      "step": 1760
    },
    {
      "epoch": 0.47941495124593714,
      "grad_norm": 1.0866303443908691,
      "learning_rate": 3.806202600216685e-05,
      "loss": 0.5932,
      "step": 1770
    },
    {
      "epoch": 0.48212351029252437,
      "grad_norm": 0.8350246548652649,
      "learning_rate": 3.799431202600217e-05,
      "loss": 0.6211,
      "step": 1780
    },
    {
      "epoch": 0.4848320693391116,
      "grad_norm": 1.4825117588043213,
      "learning_rate": 3.7926598049837486e-05,
      "loss": 0.71,
      "step": 1790
    },
    {
      "epoch": 0.4875406283856988,
      "grad_norm": 0.9949272871017456,
      "learning_rate": 3.7858884073672805e-05,
      "loss": 0.7552,
      "step": 1800
    },
    {
      "epoch": 0.490249187432286,
      "grad_norm": 1.0225255489349365,
      "learning_rate": 3.7791170097508125e-05,
      "loss": 0.5445,
      "step": 1810
    },
    {
      "epoch": 0.49295774647887325,
      "grad_norm": 0.8187614679336548,
      "learning_rate": 3.7723456121343445e-05,
      "loss": 0.5743,
      "step": 1820
    },
    {
      "epoch": 0.4956663055254605,
      "grad_norm": 1.0512133836746216,
      "learning_rate": 3.765574214517877e-05,
      "loss": 0.6663,
      "step": 1830
    },
    {
      "epoch": 0.49837486457204766,
      "grad_norm": 1.2790391445159912,
      "learning_rate": 3.758802816901409e-05,
      "loss": 0.6555,
      "step": 1840
    },
    {
      "epoch": 0.5010834236186349,
      "grad_norm": 0.8340873718261719,
      "learning_rate": 3.7520314192849404e-05,
      "loss": 0.5531,
      "step": 1850
    },
    {
      "epoch": 0.5037919826652221,
      "grad_norm": 0.8795143365859985,
      "learning_rate": 3.7452600216684724e-05,
      "loss": 0.6732,
      "step": 1860
    },
    {
      "epoch": 0.5065005417118094,
      "grad_norm": 0.8551143407821655,
      "learning_rate": 3.7384886240520044e-05,
      "loss": 0.6322,
      "step": 1870
    },
    {
      "epoch": 0.5092091007583965,
      "grad_norm": 1.010578989982605,
      "learning_rate": 3.7317172264355363e-05,
      "loss": 0.5746,
      "step": 1880
    },
    {
      "epoch": 0.5119176598049837,
      "grad_norm": 1.1748303174972534,
      "learning_rate": 3.724945828819068e-05,
      "loss": 0.6556,
      "step": 1890
    },
    {
      "epoch": 0.514626218851571,
      "grad_norm": 1.1273722648620605,
      "learning_rate": 3.718174431202601e-05,
      "loss": 0.4589,
      "step": 1900
    },
    {
      "epoch": 0.5173347778981582,
      "grad_norm": 1.1237726211547852,
      "learning_rate": 3.711403033586132e-05,
      "loss": 0.6565,
      "step": 1910
    },
    {
      "epoch": 0.5200433369447454,
      "grad_norm": 1.3719819784164429,
      "learning_rate": 3.704631635969664e-05,
      "loss": 0.6958,
      "step": 1920
    },
    {
      "epoch": 0.5227518959913326,
      "grad_norm": 0.9644774794578552,
      "learning_rate": 3.697860238353196e-05,
      "loss": 0.6688,
      "step": 1930
    },
    {
      "epoch": 0.5254604550379198,
      "grad_norm": 1.4958351850509644,
      "learning_rate": 3.691088840736728e-05,
      "loss": 0.6613,
      "step": 1940
    },
    {
      "epoch": 0.528169014084507,
      "grad_norm": 0.8774957060813904,
      "learning_rate": 3.68431744312026e-05,
      "loss": 0.6027,
      "step": 1950
    },
    {
      "epoch": 0.5308775731310943,
      "grad_norm": 0.9532380104064941,
      "learning_rate": 3.677546045503792e-05,
      "loss": 0.6355,
      "step": 1960
    },
    {
      "epoch": 0.5335861321776815,
      "grad_norm": 1.0357681512832642,
      "learning_rate": 3.670774647887324e-05,
      "loss": 0.6642,
      "step": 1970
    },
    {
      "epoch": 0.5362946912242686,
      "grad_norm": 0.9052945971488953,
      "learning_rate": 3.664003250270856e-05,
      "loss": 0.5673,
      "step": 1980
    },
    {
      "epoch": 0.5390032502708559,
      "grad_norm": 1.3622605800628662,
      "learning_rate": 3.657231852654388e-05,
      "loss": 0.6272,
      "step": 1990
    },
    {
      "epoch": 0.5417118093174431,
      "grad_norm": 0.710361123085022,
      "learning_rate": 3.65046045503792e-05,
      "loss": 0.6333,
      "step": 2000
    },
    {
      "epoch": 0.5444203683640303,
      "grad_norm": 0.9053817987442017,
      "learning_rate": 3.643689057421452e-05,
      "loss": 0.6388,
      "step": 2010
    },
    {
      "epoch": 0.5471289274106176,
      "grad_norm": 1.0585421323776245,
      "learning_rate": 3.636917659804983e-05,
      "loss": 0.5371,
      "step": 2020
    },
    {
      "epoch": 0.5498374864572048,
      "grad_norm": 1.141684651374817,
      "learning_rate": 3.630146262188516e-05,
      "loss": 0.6129,
      "step": 2030
    },
    {
      "epoch": 0.5525460455037919,
      "grad_norm": 1.0150271654129028,
      "learning_rate": 3.623374864572048e-05,
      "loss": 0.6479,
      "step": 2040
    },
    {
      "epoch": 0.5552546045503792,
      "grad_norm": 1.1798969507217407,
      "learning_rate": 3.61660346695558e-05,
      "loss": 0.6261,
      "step": 2050
    },
    {
      "epoch": 0.5579631635969664,
      "grad_norm": 0.9311688542366028,
      "learning_rate": 3.609832069339112e-05,
      "loss": 0.636,
      "step": 2060
    },
    {
      "epoch": 0.5606717226435536,
      "grad_norm": 1.086796760559082,
      "learning_rate": 3.603060671722644e-05,
      "loss": 0.6493,
      "step": 2070
    },
    {
      "epoch": 0.5633802816901409,
      "grad_norm": 0.8467773795127869,
      "learning_rate": 3.596289274106175e-05,
      "loss": 0.6067,
      "step": 2080
    },
    {
      "epoch": 0.566088840736728,
      "grad_norm": 1.3616284132003784,
      "learning_rate": 3.589517876489707e-05,
      "loss": 0.5133,
      "step": 2090
    },
    {
      "epoch": 0.5687973997833152,
      "grad_norm": 0.9150554537773132,
      "learning_rate": 3.58274647887324e-05,
      "loss": 0.595,
      "step": 2100
    },
    {
      "epoch": 0.5715059588299025,
      "grad_norm": 0.8681939244270325,
      "learning_rate": 3.575975081256772e-05,
      "loss": 0.6026,
      "step": 2110
    },
    {
      "epoch": 0.5742145178764897,
      "grad_norm": 1.1319694519042969,
      "learning_rate": 3.569203683640304e-05,
      "loss": 0.6475,
      "step": 2120
    },
    {
      "epoch": 0.5769230769230769,
      "grad_norm": 0.9470303654670715,
      "learning_rate": 3.562432286023836e-05,
      "loss": 0.7072,
      "step": 2130
    },
    {
      "epoch": 0.5796316359696642,
      "grad_norm": 1.0763996839523315,
      "learning_rate": 3.555660888407367e-05,
      "loss": 0.5576,
      "step": 2140
    },
    {
      "epoch": 0.5823401950162513,
      "grad_norm": 0.989501416683197,
      "learning_rate": 3.548889490790899e-05,
      "loss": 0.5825,
      "step": 2150
    },
    {
      "epoch": 0.5850487540628385,
      "grad_norm": 0.7915301322937012,
      "learning_rate": 3.542118093174431e-05,
      "loss": 0.6097,
      "step": 2160
    },
    {
      "epoch": 0.5877573131094258,
      "grad_norm": 0.8555750846862793,
      "learning_rate": 3.5353466955579637e-05,
      "loss": 0.5956,
      "step": 2170
    },
    {
      "epoch": 0.590465872156013,
      "grad_norm": 0.852286696434021,
      "learning_rate": 3.5285752979414956e-05,
      "loss": 0.6009,
      "step": 2180
    },
    {
      "epoch": 0.5931744312026003,
      "grad_norm": 0.7624678611755371,
      "learning_rate": 3.5218039003250276e-05,
      "loss": 0.6523,
      "step": 2190
    },
    {
      "epoch": 0.5958829902491874,
      "grad_norm": 1.4006997346878052,
      "learning_rate": 3.515032502708559e-05,
      "loss": 0.5818,
      "step": 2200
    },
    {
      "epoch": 0.5985915492957746,
      "grad_norm": 0.836459755897522,
      "learning_rate": 3.508261105092091e-05,
      "loss": 0.5274,
      "step": 2210
    },
    {
      "epoch": 0.6013001083423619,
      "grad_norm": 0.9456753134727478,
      "learning_rate": 3.501489707475623e-05,
      "loss": 0.5947,
      "step": 2220
    },
    {
      "epoch": 0.6040086673889491,
      "grad_norm": 0.9041709899902344,
      "learning_rate": 3.494718309859155e-05,
      "loss": 0.6728,
      "step": 2230
    },
    {
      "epoch": 0.6067172264355363,
      "grad_norm": 1.126310110092163,
      "learning_rate": 3.4879469122426875e-05,
      "loss": 0.6681,
      "step": 2240
    },
    {
      "epoch": 0.6094257854821236,
      "grad_norm": 0.9466851353645325,
      "learning_rate": 3.4811755146262195e-05,
      "loss": 0.5482,
      "step": 2250
    },
    {
      "epoch": 0.6121343445287107,
      "grad_norm": 0.847705602645874,
      "learning_rate": 3.474404117009751e-05,
      "loss": 0.591,
      "step": 2260
    },
    {
      "epoch": 0.6148429035752979,
      "grad_norm": 1.103165864944458,
      "learning_rate": 3.467632719393283e-05,
      "loss": 0.5684,
      "step": 2270
    },
    {
      "epoch": 0.6175514626218852,
      "grad_norm": 1.0534892082214355,
      "learning_rate": 3.460861321776815e-05,
      "loss": 0.6899,
      "step": 2280
    },
    {
      "epoch": 0.6202600216684724,
      "grad_norm": 1.228432297706604,
      "learning_rate": 3.454089924160347e-05,
      "loss": 0.6702,
      "step": 2290
    },
    {
      "epoch": 0.6229685807150596,
      "grad_norm": 1.0028400421142578,
      "learning_rate": 3.447318526543879e-05,
      "loss": 0.5432,
      "step": 2300
    },
    {
      "epoch": 0.6256771397616468,
      "grad_norm": 1.0683753490447998,
      "learning_rate": 3.440547128927411e-05,
      "loss": 0.5781,
      "step": 2310
    },
    {
      "epoch": 0.628385698808234,
      "grad_norm": 1.1172510385513306,
      "learning_rate": 3.4337757313109426e-05,
      "loss": 0.5633,
      "step": 2320
    },
    {
      "epoch": 0.6310942578548212,
      "grad_norm": 0.940650224685669,
      "learning_rate": 3.4270043336944746e-05,
      "loss": 0.5614,
      "step": 2330
    },
    {
      "epoch": 0.6338028169014085,
      "grad_norm": 1.1654393672943115,
      "learning_rate": 3.4202329360780066e-05,
      "loss": 0.5632,
      "step": 2340
    },
    {
      "epoch": 0.6365113759479957,
      "grad_norm": 1.1373010873794556,
      "learning_rate": 3.4134615384615386e-05,
      "loss": 0.5934,
      "step": 2350
    },
    {
      "epoch": 0.6392199349945829,
      "grad_norm": 1.3417432308197021,
      "learning_rate": 3.4066901408450705e-05,
      "loss": 0.7366,
      "step": 2360
    },
    {
      "epoch": 0.6419284940411701,
      "grad_norm": 1.1136654615402222,
      "learning_rate": 3.3999187432286025e-05,
      "loss": 0.66,
      "step": 2370
    },
    {
      "epoch": 0.6446370530877573,
      "grad_norm": 0.8917647004127502,
      "learning_rate": 3.3931473456121345e-05,
      "loss": 0.637,
      "step": 2380
    },
    {
      "epoch": 0.6473456121343445,
      "grad_norm": 0.7093636989593506,
      "learning_rate": 3.3863759479956665e-05,
      "loss": 0.6493,
      "step": 2390
    },
    {
      "epoch": 0.6500541711809318,
      "grad_norm": 0.7737234234809875,
      "learning_rate": 3.3796045503791984e-05,
      "loss": 0.5416,
      "step": 2400
    },
    {
      "epoch": 0.652762730227519,
      "grad_norm": 0.9868422746658325,
      "learning_rate": 3.3728331527627304e-05,
      "loss": 0.6652,
      "step": 2410
    },
    {
      "epoch": 0.6554712892741061,
      "grad_norm": 1.013222098350525,
      "learning_rate": 3.3660617551462624e-05,
      "loss": 0.5405,
      "step": 2420
    },
    {
      "epoch": 0.6581798483206934,
      "grad_norm": 1.0149226188659668,
      "learning_rate": 3.3592903575297944e-05,
      "loss": 0.6958,
      "step": 2430
    },
    {
      "epoch": 0.6608884073672806,
      "grad_norm": 0.8999015688896179,
      "learning_rate": 3.3525189599133263e-05,
      "loss": 0.6503,
      "step": 2440
    },
    {
      "epoch": 0.6635969664138678,
      "grad_norm": 1.1058539152145386,
      "learning_rate": 3.345747562296858e-05,
      "loss": 0.7109,
      "step": 2450
    },
    {
      "epoch": 0.6663055254604551,
      "grad_norm": 0.996398389339447,
      "learning_rate": 3.33897616468039e-05,
      "loss": 0.631,
      "step": 2460
    },
    {
      "epoch": 0.6690140845070423,
      "grad_norm": 0.7702249884605408,
      "learning_rate": 3.332204767063922e-05,
      "loss": 0.5322,
      "step": 2470
    },
    {
      "epoch": 0.6717226435536294,
      "grad_norm": 0.8027637600898743,
      "learning_rate": 3.325433369447454e-05,
      "loss": 0.5838,
      "step": 2480
    },
    {
      "epoch": 0.6744312026002167,
      "grad_norm": 0.9726614952087402,
      "learning_rate": 3.3186619718309855e-05,
      "loss": 0.6402,
      "step": 2490
    },
    {
      "epoch": 0.6771397616468039,
      "grad_norm": 1.2495347261428833,
      "learning_rate": 3.311890574214518e-05,
      "loss": 0.6955,
      "step": 2500
    },
    {
      "epoch": 0.6798483206933911,
      "grad_norm": 0.8722555041313171,
      "learning_rate": 3.30511917659805e-05,
      "loss": 0.6774,
      "step": 2510
    },
    {
      "epoch": 0.6825568797399784,
      "grad_norm": 0.9305258393287659,
      "learning_rate": 3.298347778981582e-05,
      "loss": 0.5238,
      "step": 2520
    },
    {
      "epoch": 0.6852654387865655,
      "grad_norm": 0.8113645911216736,
      "learning_rate": 3.291576381365114e-05,
      "loss": 0.7337,
      "step": 2530
    },
    {
      "epoch": 0.6879739978331527,
      "grad_norm": 1.7588331699371338,
      "learning_rate": 3.284804983748646e-05,
      "loss": 0.5751,
      "step": 2540
    },
    {
      "epoch": 0.69068255687974,
      "grad_norm": 1.2765791416168213,
      "learning_rate": 3.2780335861321774e-05,
      "loss": 0.6462,
      "step": 2550
    },
    {
      "epoch": 0.6933911159263272,
      "grad_norm": 1.198242425918579,
      "learning_rate": 3.2712621885157094e-05,
      "loss": 0.7562,
      "step": 2560
    },
    {
      "epoch": 0.6960996749729144,
      "grad_norm": 0.7611933946609497,
      "learning_rate": 3.264490790899242e-05,
      "loss": 0.6856,
      "step": 2570
    },
    {
      "epoch": 0.6988082340195017,
      "grad_norm": 0.9769574403762817,
      "learning_rate": 3.257719393282774e-05,
      "loss": 0.7051,
      "step": 2580
    },
    {
      "epoch": 0.7015167930660888,
      "grad_norm": 1.4931994676589966,
      "learning_rate": 3.250947995666306e-05,
      "loss": 0.6379,
      "step": 2590
    },
    {
      "epoch": 0.704225352112676,
      "grad_norm": 1.037959098815918,
      "learning_rate": 3.244176598049838e-05,
      "loss": 0.651,
      "step": 2600
    },
    {
      "epoch": 0.7069339111592633,
      "grad_norm": 0.7172039747238159,
      "learning_rate": 3.237405200433369e-05,
      "loss": 0.6093,
      "step": 2610
    },
    {
      "epoch": 0.7096424702058505,
      "grad_norm": 1.0177899599075317,
      "learning_rate": 3.230633802816901e-05,
      "loss": 0.5963,
      "step": 2620
    },
    {
      "epoch": 0.7123510292524377,
      "grad_norm": 1.1052550077438354,
      "learning_rate": 3.223862405200433e-05,
      "loss": 0.6431,
      "step": 2630
    },
    {
      "epoch": 0.7150595882990249,
      "grad_norm": 0.9191675186157227,
      "learning_rate": 3.217091007583966e-05,
      "loss": 0.6489,
      "step": 2640
    },
    {
      "epoch": 0.7177681473456121,
      "grad_norm": 0.959445595741272,
      "learning_rate": 3.210319609967498e-05,
      "loss": 0.6028,
      "step": 2650
    },
    {
      "epoch": 0.7204767063921993,
      "grad_norm": 1.043451189994812,
      "learning_rate": 3.20354821235103e-05,
      "loss": 0.554,
      "step": 2660
    },
    {
      "epoch": 0.7231852654387866,
      "grad_norm": 1.0230214595794678,
      "learning_rate": 3.196776814734561e-05,
      "loss": 0.5505,
      "step": 2670
    },
    {
      "epoch": 0.7258938244853738,
      "grad_norm": 1.2582981586456299,
      "learning_rate": 3.190005417118093e-05,
      "loss": 0.6265,
      "step": 2680
    },
    {
      "epoch": 0.728602383531961,
      "grad_norm": 0.9621735215187073,
      "learning_rate": 3.183234019501625e-05,
      "loss": 0.6458,
      "step": 2690
    },
    {
      "epoch": 0.7313109425785482,
      "grad_norm": 1.0511274337768555,
      "learning_rate": 3.176462621885157e-05,
      "loss": 0.5301,
      "step": 2700
    },
    {
      "epoch": 0.7340195016251354,
      "grad_norm": 0.9405847191810608,
      "learning_rate": 3.16969122426869e-05,
      "loss": 0.6285,
      "step": 2710
    },
    {
      "epoch": 0.7367280606717227,
      "grad_norm": 1.0739988088607788,
      "learning_rate": 3.162919826652222e-05,
      "loss": 0.5705,
      "step": 2720
    },
    {
      "epoch": 0.7394366197183099,
      "grad_norm": 0.8355377316474915,
      "learning_rate": 3.156148429035753e-05,
      "loss": 0.6237,
      "step": 2730
    },
    {
      "epoch": 0.742145178764897,
      "grad_norm": 0.9356459379196167,
      "learning_rate": 3.149377031419285e-05,
      "loss": 0.5775,
      "step": 2740
    },
    {
      "epoch": 0.7448537378114843,
      "grad_norm": 0.8903749585151672,
      "learning_rate": 3.142605633802817e-05,
      "loss": 0.6057,
      "step": 2750
    },
    {
      "epoch": 0.7475622968580715,
      "grad_norm": 0.9275684952735901,
      "learning_rate": 3.135834236186349e-05,
      "loss": 0.5821,
      "step": 2760
    },
    {
      "epoch": 0.7502708559046587,
      "grad_norm": 2.0586953163146973,
      "learning_rate": 3.129062838569881e-05,
      "loss": 0.6566,
      "step": 2770
    },
    {
      "epoch": 0.752979414951246,
      "grad_norm": 0.9673906564712524,
      "learning_rate": 3.122291440953413e-05,
      "loss": 0.5901,
      "step": 2780
    },
    {
      "epoch": 0.7556879739978332,
      "grad_norm": 1.4157249927520752,
      "learning_rate": 3.115520043336945e-05,
      "loss": 0.6602,
      "step": 2790
    },
    {
      "epoch": 0.7583965330444203,
      "grad_norm": 1.0881435871124268,
      "learning_rate": 3.108748645720477e-05,
      "loss": 0.6069,
      "step": 2800
    },
    {
      "epoch": 0.7611050920910076,
      "grad_norm": 1.2872613668441772,
      "learning_rate": 3.101977248104009e-05,
      "loss": 0.5173,
      "step": 2810
    },
    {
      "epoch": 0.7638136511375948,
      "grad_norm": 1.2167001962661743,
      "learning_rate": 3.095205850487541e-05,
      "loss": 0.5842,
      "step": 2820
    },
    {
      "epoch": 0.766522210184182,
      "grad_norm": 1.1401606798171997,
      "learning_rate": 3.088434452871073e-05,
      "loss": 0.5563,
      "step": 2830
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.9237706661224365,
      "learning_rate": 3.081663055254605e-05,
      "loss": 0.6018,
      "step": 2840
    },
    {
      "epoch": 0.7719393282773565,
      "grad_norm": 1.0028389692306519,
      "learning_rate": 3.074891657638137e-05,
      "loss": 0.661,
      "step": 2850
    },
    {
      "epoch": 0.7746478873239436,
      "grad_norm": 1.1081323623657227,
      "learning_rate": 3.068120260021669e-05,
      "loss": 0.5269,
      "step": 2860
    },
    {
      "epoch": 0.7773564463705309,
      "grad_norm": 0.9093417525291443,
      "learning_rate": 3.0613488624052006e-05,
      "loss": 0.6064,
      "step": 2870
    },
    {
      "epoch": 0.7800650054171181,
      "grad_norm": 1.130020022392273,
      "learning_rate": 3.0545774647887326e-05,
      "loss": 0.658,
      "step": 2880
    },
    {
      "epoch": 0.7827735644637053,
      "grad_norm": 1.1307576894760132,
      "learning_rate": 3.0478060671722646e-05,
      "loss": 0.6468,
      "step": 2890
    },
    {
      "epoch": 0.7854821235102926,
      "grad_norm": 0.9761281609535217,
      "learning_rate": 3.0410346695557962e-05,
      "loss": 0.6522,
      "step": 2900
    },
    {
      "epoch": 0.7881906825568797,
      "grad_norm": 0.8906084299087524,
      "learning_rate": 3.0342632719393282e-05,
      "loss": 0.6022,
      "step": 2910
    },
    {
      "epoch": 0.7908992416034669,
      "grad_norm": 1.3195003271102905,
      "learning_rate": 3.0274918743228602e-05,
      "loss": 0.6213,
      "step": 2920
    },
    {
      "epoch": 0.7936078006500542,
      "grad_norm": 0.8056520223617554,
      "learning_rate": 3.0207204767063925e-05,
      "loss": 0.6236,
      "step": 2930
    },
    {
      "epoch": 0.7963163596966414,
      "grad_norm": 1.11085844039917,
      "learning_rate": 3.0139490790899245e-05,
      "loss": 0.7718,
      "step": 2940
    },
    {
      "epoch": 0.7990249187432286,
      "grad_norm": 0.8989255428314209,
      "learning_rate": 3.0071776814734565e-05,
      "loss": 0.6597,
      "step": 2950
    },
    {
      "epoch": 0.8017334777898159,
      "grad_norm": 0.9057942628860474,
      "learning_rate": 3.000406283856988e-05,
      "loss": 0.5918,
      "step": 2960
    },
    {
      "epoch": 0.804442036836403,
      "grad_norm": 1.1019989252090454,
      "learning_rate": 2.99363488624052e-05,
      "loss": 0.4633,
      "step": 2970
    },
    {
      "epoch": 0.8071505958829902,
      "grad_norm": 1.1748385429382324,
      "learning_rate": 2.986863488624052e-05,
      "loss": 0.7144,
      "step": 2980
    },
    {
      "epoch": 0.8098591549295775,
      "grad_norm": 1.2527467012405396,
      "learning_rate": 2.980092091007584e-05,
      "loss": 0.5917,
      "step": 2990
    },
    {
      "epoch": 0.8125677139761647,
      "grad_norm": 0.992548406124115,
      "learning_rate": 2.9733206933911163e-05,
      "loss": 0.6498,
      "step": 3000
    },
    {
      "epoch": 0.8152762730227519,
      "grad_norm": 0.9734187722206116,
      "learning_rate": 2.9665492957746483e-05,
      "loss": 0.6506,
      "step": 3010
    },
    {
      "epoch": 0.8179848320693391,
      "grad_norm": 1.481888771057129,
      "learning_rate": 2.9597778981581796e-05,
      "loss": 0.6701,
      "step": 3020
    },
    {
      "epoch": 0.8206933911159263,
      "grad_norm": 0.9067819118499756,
      "learning_rate": 2.953006500541712e-05,
      "loss": 0.5842,
      "step": 3030
    },
    {
      "epoch": 0.8234019501625135,
      "grad_norm": 0.9727799892425537,
      "learning_rate": 2.946235102925244e-05,
      "loss": 0.5544,
      "step": 3040
    },
    {
      "epoch": 0.8261105092091008,
      "grad_norm": 0.913337230682373,
      "learning_rate": 2.939463705308776e-05,
      "loss": 0.5975,
      "step": 3050
    },
    {
      "epoch": 0.828819068255688,
      "grad_norm": 0.9764694571495056,
      "learning_rate": 2.932692307692308e-05,
      "loss": 0.5532,
      "step": 3060
    },
    {
      "epoch": 0.8315276273022751,
      "grad_norm": 1.6737520694732666,
      "learning_rate": 2.92592091007584e-05,
      "loss": 0.661,
      "step": 3070
    },
    {
      "epoch": 0.8342361863488624,
      "grad_norm": 1.1464840173721313,
      "learning_rate": 2.9191495124593715e-05,
      "loss": 0.6325,
      "step": 3080
    },
    {
      "epoch": 0.8369447453954496,
      "grad_norm": 0.9044196009635925,
      "learning_rate": 2.9123781148429034e-05,
      "loss": 0.7463,
      "step": 3090
    },
    {
      "epoch": 0.8396533044420368,
      "grad_norm": 1.0601863861083984,
      "learning_rate": 2.9056067172264358e-05,
      "loss": 0.7461,
      "step": 3100
    },
    {
      "epoch": 0.8423618634886241,
      "grad_norm": 2.3503470420837402,
      "learning_rate": 2.8988353196099677e-05,
      "loss": 0.5827,
      "step": 3110
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 0.8772419691085815,
      "learning_rate": 2.8920639219934997e-05,
      "loss": 0.6658,
      "step": 3120
    },
    {
      "epoch": 0.8477789815817984,
      "grad_norm": 1.095036268234253,
      "learning_rate": 2.8852925243770317e-05,
      "loss": 0.6902,
      "step": 3130
    },
    {
      "epoch": 0.8504875406283857,
      "grad_norm": 0.7258532047271729,
      "learning_rate": 2.8785211267605633e-05,
      "loss": 0.5953,
      "step": 3140
    },
    {
      "epoch": 0.8531960996749729,
      "grad_norm": 0.9976251721382141,
      "learning_rate": 2.8717497291440953e-05,
      "loss": 0.7214,
      "step": 3150
    },
    {
      "epoch": 0.8559046587215602,
      "grad_norm": 0.9394791126251221,
      "learning_rate": 2.8649783315276273e-05,
      "loss": 0.6094,
      "step": 3160
    },
    {
      "epoch": 0.8586132177681474,
      "grad_norm": 1.2056626081466675,
      "learning_rate": 2.8582069339111596e-05,
      "loss": 0.5845,
      "step": 3170
    },
    {
      "epoch": 0.8613217768147345,
      "grad_norm": 0.9336312413215637,
      "learning_rate": 2.8514355362946916e-05,
      "loss": 0.5404,
      "step": 3180
    },
    {
      "epoch": 0.8640303358613218,
      "grad_norm": 1.0082979202270508,
      "learning_rate": 2.8446641386782235e-05,
      "loss": 0.5878,
      "step": 3190
    },
    {
      "epoch": 0.866738894907909,
      "grad_norm": 0.9852952361106873,
      "learning_rate": 2.8378927410617552e-05,
      "loss": 0.6051,
      "step": 3200
    },
    {
      "epoch": 0.8694474539544962,
      "grad_norm": 0.9232460260391235,
      "learning_rate": 2.831121343445287e-05,
      "loss": 0.6862,
      "step": 3210
    },
    {
      "epoch": 0.8721560130010835,
      "grad_norm": 1.2404117584228516,
      "learning_rate": 2.824349945828819e-05,
      "loss": 0.598,
      "step": 3220
    },
    {
      "epoch": 0.8748645720476707,
      "grad_norm": 1.1290674209594727,
      "learning_rate": 2.817578548212351e-05,
      "loss": 0.7605,
      "step": 3230
    },
    {
      "epoch": 0.8775731310942578,
      "grad_norm": 1.0875903367996216,
      "learning_rate": 2.8108071505958834e-05,
      "loss": 0.5512,
      "step": 3240
    },
    {
      "epoch": 0.8802816901408451,
      "grad_norm": 1.0324491262435913,
      "learning_rate": 2.8040357529794154e-05,
      "loss": 0.6654,
      "step": 3250
    },
    {
      "epoch": 0.8829902491874323,
      "grad_norm": 1.1600542068481445,
      "learning_rate": 2.7972643553629467e-05,
      "loss": 0.6747,
      "step": 3260
    },
    {
      "epoch": 0.8856988082340195,
      "grad_norm": 0.9544820785522461,
      "learning_rate": 2.790492957746479e-05,
      "loss": 0.618,
      "step": 3270
    },
    {
      "epoch": 0.8884073672806068,
      "grad_norm": 0.8290045261383057,
      "learning_rate": 2.783721560130011e-05,
      "loss": 0.5167,
      "step": 3280
    },
    {
      "epoch": 0.8911159263271939,
      "grad_norm": 0.8405312895774841,
      "learning_rate": 2.776950162513543e-05,
      "loss": 0.5536,
      "step": 3290
    },
    {
      "epoch": 0.8938244853737811,
      "grad_norm": 1.1216707229614258,
      "learning_rate": 2.770178764897075e-05,
      "loss": 0.6665,
      "step": 3300
    },
    {
      "epoch": 0.8965330444203684,
      "grad_norm": 1.1675693988800049,
      "learning_rate": 2.7634073672806073e-05,
      "loss": 0.6001,
      "step": 3310
    },
    {
      "epoch": 0.8992416034669556,
      "grad_norm": 1.1178948879241943,
      "learning_rate": 2.7566359696641386e-05,
      "loss": 0.6947,
      "step": 3320
    },
    {
      "epoch": 0.9019501625135428,
      "grad_norm": 1.120407223701477,
      "learning_rate": 2.7498645720476705e-05,
      "loss": 0.6949,
      "step": 3330
    },
    {
      "epoch": 0.90465872156013,
      "grad_norm": 0.9516069293022156,
      "learning_rate": 2.743093174431203e-05,
      "loss": 0.548,
      "step": 3340
    },
    {
      "epoch": 0.9073672806067172,
      "grad_norm": 1.2876793146133423,
      "learning_rate": 2.7363217768147348e-05,
      "loss": 0.656,
      "step": 3350
    },
    {
      "epoch": 0.9100758396533044,
      "grad_norm": 1.02908194065094,
      "learning_rate": 2.7295503791982668e-05,
      "loss": 0.669,
      "step": 3360
    },
    {
      "epoch": 0.9127843986998917,
      "grad_norm": 1.075605869293213,
      "learning_rate": 2.7227789815817984e-05,
      "loss": 0.5946,
      "step": 3370
    },
    {
      "epoch": 0.9154929577464789,
      "grad_norm": 1.1098593473434448,
      "learning_rate": 2.7160075839653304e-05,
      "loss": 0.5578,
      "step": 3380
    },
    {
      "epoch": 0.918201516793066,
      "grad_norm": 0.9142598509788513,
      "learning_rate": 2.7092361863488624e-05,
      "loss": 0.5608,
      "step": 3390
    },
    {
      "epoch": 0.9209100758396533,
      "grad_norm": 1.3002526760101318,
      "learning_rate": 2.7024647887323944e-05,
      "loss": 0.607,
      "step": 3400
    },
    {
      "epoch": 0.9236186348862405,
      "grad_norm": 1.1076070070266724,
      "learning_rate": 2.6956933911159267e-05,
      "loss": 0.6474,
      "step": 3410
    },
    {
      "epoch": 0.9263271939328277,
      "grad_norm": 0.9264060258865356,
      "learning_rate": 2.6889219934994587e-05,
      "loss": 0.5769,
      "step": 3420
    },
    {
      "epoch": 0.929035752979415,
      "grad_norm": 1.308052659034729,
      "learning_rate": 2.68215059588299e-05,
      "loss": 0.6317,
      "step": 3430
    },
    {
      "epoch": 0.9317443120260022,
      "grad_norm": 0.8364198803901672,
      "learning_rate": 2.6753791982665223e-05,
      "loss": 0.6581,
      "step": 3440
    },
    {
      "epoch": 0.9344528710725893,
      "grad_norm": 0.8980187773704529,
      "learning_rate": 2.6686078006500542e-05,
      "loss": 0.5985,
      "step": 3450
    },
    {
      "epoch": 0.9371614301191766,
      "grad_norm": 1.0479673147201538,
      "learning_rate": 2.6618364030335862e-05,
      "loss": 0.6664,
      "step": 3460
    },
    {
      "epoch": 0.9398699891657638,
      "grad_norm": 1.1500802040100098,
      "learning_rate": 2.6550650054171182e-05,
      "loss": 0.6723,
      "step": 3470
    },
    {
      "epoch": 0.942578548212351,
      "grad_norm": 1.042648434638977,
      "learning_rate": 2.6482936078006505e-05,
      "loss": 0.6272,
      "step": 3480
    },
    {
      "epoch": 0.9452871072589383,
      "grad_norm": 0.9673088192939758,
      "learning_rate": 2.6415222101841818e-05,
      "loss": 0.5066,
      "step": 3490
    },
    {
      "epoch": 0.9479956663055255,
      "grad_norm": 0.9353731274604797,
      "learning_rate": 2.6347508125677138e-05,
      "loss": 0.4982,
      "step": 3500
    },
    {
      "epoch": 0.9507042253521126,
      "grad_norm": 0.9095314741134644,
      "learning_rate": 2.627979414951246e-05,
      "loss": 0.5929,
      "step": 3510
    },
    {
      "epoch": 0.9534127843986999,
      "grad_norm": 0.8717288374900818,
      "learning_rate": 2.621208017334778e-05,
      "loss": 0.5544,
      "step": 3520
    },
    {
      "epoch": 0.9561213434452871,
      "grad_norm": 1.1771354675292969,
      "learning_rate": 2.61443661971831e-05,
      "loss": 0.6815,
      "step": 3530
    },
    {
      "epoch": 0.9588299024918743,
      "grad_norm": 1.1462717056274414,
      "learning_rate": 2.607665222101842e-05,
      "loss": 0.7219,
      "step": 3540
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 1.1494147777557373,
      "learning_rate": 2.6008938244853737e-05,
      "loss": 0.6921,
      "step": 3550
    },
    {
      "epoch": 0.9642470205850487,
      "grad_norm": 0.9625498652458191,
      "learning_rate": 2.5941224268689056e-05,
      "loss": 0.678,
      "step": 3560
    },
    {
      "epoch": 0.9669555796316359,
      "grad_norm": 0.8859768509864807,
      "learning_rate": 2.5873510292524376e-05,
      "loss": 0.6939,
      "step": 3570
    },
    {
      "epoch": 0.9696641386782232,
      "grad_norm": 0.8676744103431702,
      "learning_rate": 2.58057963163597e-05,
      "loss": 0.5472,
      "step": 3580
    },
    {
      "epoch": 0.9723726977248104,
      "grad_norm": 0.8691466450691223,
      "learning_rate": 2.573808234019502e-05,
      "loss": 0.6357,
      "step": 3590
    },
    {
      "epoch": 0.9750812567713976,
      "grad_norm": 0.8134922981262207,
      "learning_rate": 2.567036836403034e-05,
      "loss": 0.5847,
      "step": 3600
    },
    {
      "epoch": 0.9777898158179849,
      "grad_norm": 1.1096259355545044,
      "learning_rate": 2.5602654387865655e-05,
      "loss": 0.7167,
      "step": 3610
    },
    {
      "epoch": 0.980498374864572,
      "grad_norm": 1.1858456134796143,
      "learning_rate": 2.5534940411700975e-05,
      "loss": 0.602,
      "step": 3620
    },
    {
      "epoch": 0.9832069339111592,
      "grad_norm": 1.1711441278457642,
      "learning_rate": 2.5467226435536295e-05,
      "loss": 0.5202,
      "step": 3630
    },
    {
      "epoch": 0.9859154929577465,
      "grad_norm": 1.2971404790878296,
      "learning_rate": 2.5399512459371615e-05,
      "loss": 0.576,
      "step": 3640
    },
    {
      "epoch": 0.9886240520043337,
      "grad_norm": 1.2716292142868042,
      "learning_rate": 2.5331798483206938e-05,
      "loss": 0.7249,
      "step": 3650
    },
    {
      "epoch": 0.991332611050921,
      "grad_norm": 0.9889577031135559,
      "learning_rate": 2.5264084507042258e-05,
      "loss": 0.6438,
      "step": 3660
    },
    {
      "epoch": 0.9940411700975081,
      "grad_norm": 1.1577321290969849,
      "learning_rate": 2.519637053087757e-05,
      "loss": 0.5947,
      "step": 3670
    },
    {
      "epoch": 0.9967497291440953,
      "grad_norm": 1.1093019247055054,
      "learning_rate": 2.5128656554712894e-05,
      "loss": 0.6824,
      "step": 3680
    },
    {
      "epoch": 0.9994582881906826,
      "grad_norm": 1.0781413316726685,
      "learning_rate": 2.5060942578548213e-05,
      "loss": 0.4332,
      "step": 3690
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6183221340179443,
      "eval_runtime": 168.5134,
      "eval_samples_per_second": 9.738,
      "eval_steps_per_second": 2.439,
      "step": 3692
    },
    {
      "epoch": 1.0021668472372698,
      "grad_norm": 0.9985407590866089,
      "learning_rate": 2.4993228602383533e-05,
      "loss": 0.556,
      "step": 3700
    },
    {
      "epoch": 1.004875406283857,
      "grad_norm": 0.851854145526886,
      "learning_rate": 2.4925514626218853e-05,
      "loss": 0.5131,
      "step": 3710
    },
    {
      "epoch": 1.0075839653304441,
      "grad_norm": 1.086839199066162,
      "learning_rate": 2.4857800650054173e-05,
      "loss": 0.5148,
      "step": 3720
    },
    {
      "epoch": 1.0102925243770313,
      "grad_norm": 0.9639433026313782,
      "learning_rate": 2.4790086673889492e-05,
      "loss": 0.5379,
      "step": 3730
    },
    {
      "epoch": 1.0130010834236187,
      "grad_norm": 1.2458070516586304,
      "learning_rate": 2.472237269772481e-05,
      "loss": 0.5852,
      "step": 3740
    },
    {
      "epoch": 1.015709642470206,
      "grad_norm": 1.092647671699524,
      "learning_rate": 2.4654658721560132e-05,
      "loss": 0.5121,
      "step": 3750
    },
    {
      "epoch": 1.018418201516793,
      "grad_norm": 1.4972783327102661,
      "learning_rate": 2.4586944745395452e-05,
      "loss": 0.6665,
      "step": 3760
    },
    {
      "epoch": 1.0211267605633803,
      "grad_norm": 0.9923796057701111,
      "learning_rate": 2.4519230769230768e-05,
      "loss": 0.5318,
      "step": 3770
    },
    {
      "epoch": 1.0238353196099674,
      "grad_norm": 1.2493774890899658,
      "learning_rate": 2.445151679306609e-05,
      "loss": 0.6012,
      "step": 3780
    },
    {
      "epoch": 1.0265438786565546,
      "grad_norm": 0.7992334365844727,
      "learning_rate": 2.438380281690141e-05,
      "loss": 0.6293,
      "step": 3790
    },
    {
      "epoch": 1.029252437703142,
      "grad_norm": 0.8925365209579468,
      "learning_rate": 2.4316088840736727e-05,
      "loss": 0.5562,
      "step": 3800
    },
    {
      "epoch": 1.0319609967497292,
      "grad_norm": 1.2848116159439087,
      "learning_rate": 2.4248374864572047e-05,
      "loss": 0.6147,
      "step": 3810
    },
    {
      "epoch": 1.0346695557963164,
      "grad_norm": 0.7952027916908264,
      "learning_rate": 2.418066088840737e-05,
      "loss": 0.4747,
      "step": 3820
    },
    {
      "epoch": 1.0373781148429035,
      "grad_norm": 0.9829370379447937,
      "learning_rate": 2.4112946912242687e-05,
      "loss": 0.6636,
      "step": 3830
    },
    {
      "epoch": 1.0400866738894907,
      "grad_norm": 1.0974098443984985,
      "learning_rate": 2.4045232936078006e-05,
      "loss": 0.6884,
      "step": 3840
    },
    {
      "epoch": 1.042795232936078,
      "grad_norm": 1.2372184991836548,
      "learning_rate": 2.397751895991333e-05,
      "loss": 0.5578,
      "step": 3850
    },
    {
      "epoch": 1.0455037919826653,
      "grad_norm": 0.9532913565635681,
      "learning_rate": 2.3909804983748646e-05,
      "loss": 0.5867,
      "step": 3860
    },
    {
      "epoch": 1.0482123510292525,
      "grad_norm": 0.9731175303459167,
      "learning_rate": 2.3842091007583966e-05,
      "loss": 0.6068,
      "step": 3870
    },
    {
      "epoch": 1.0509209100758397,
      "grad_norm": 0.9508776664733887,
      "learning_rate": 2.3774377031419286e-05,
      "loss": 0.5679,
      "step": 3880
    },
    {
      "epoch": 1.0536294691224268,
      "grad_norm": 1.358424186706543,
      "learning_rate": 2.3706663055254605e-05,
      "loss": 0.533,
      "step": 3890
    },
    {
      "epoch": 1.056338028169014,
      "grad_norm": 1.0485457181930542,
      "learning_rate": 2.3638949079089925e-05,
      "loss": 0.5851,
      "step": 3900
    },
    {
      "epoch": 1.0590465872156014,
      "grad_norm": 1.345656156539917,
      "learning_rate": 2.3571235102925245e-05,
      "loss": 0.6207,
      "step": 3910
    },
    {
      "epoch": 1.0617551462621886,
      "grad_norm": 1.0483790636062622,
      "learning_rate": 2.3503521126760565e-05,
      "loss": 0.6408,
      "step": 3920
    },
    {
      "epoch": 1.0644637053087758,
      "grad_norm": 1.1926522254943848,
      "learning_rate": 2.3435807150595884e-05,
      "loss": 0.6769,
      "step": 3930
    },
    {
      "epoch": 1.067172264355363,
      "grad_norm": 1.1498827934265137,
      "learning_rate": 2.3368093174431204e-05,
      "loss": 0.6749,
      "step": 3940
    },
    {
      "epoch": 1.0698808234019501,
      "grad_norm": 0.8818507194519043,
      "learning_rate": 2.3300379198266524e-05,
      "loss": 0.5225,
      "step": 3950
    },
    {
      "epoch": 1.0725893824485373,
      "grad_norm": 1.0169944763183594,
      "learning_rate": 2.3232665222101844e-05,
      "loss": 0.7018,
      "step": 3960
    },
    {
      "epoch": 1.0752979414951245,
      "grad_norm": 0.922850489616394,
      "learning_rate": 2.3164951245937163e-05,
      "loss": 0.5919,
      "step": 3970
    },
    {
      "epoch": 1.0780065005417119,
      "grad_norm": 0.975191056728363,
      "learning_rate": 2.3097237269772483e-05,
      "loss": 0.665,
      "step": 3980
    },
    {
      "epoch": 1.080715059588299,
      "grad_norm": 1.0354785919189453,
      "learning_rate": 2.3029523293607803e-05,
      "loss": 0.6289,
      "step": 3990
    },
    {
      "epoch": 1.0834236186348862,
      "grad_norm": 0.8741968870162964,
      "learning_rate": 2.2961809317443123e-05,
      "loss": 0.583,
      "step": 4000
    },
    {
      "epoch": 1.0861321776814734,
      "grad_norm": 1.1101526021957397,
      "learning_rate": 2.289409534127844e-05,
      "loss": 0.5782,
      "step": 4010
    },
    {
      "epoch": 1.0888407367280606,
      "grad_norm": 1.135534644126892,
      "learning_rate": 2.2826381365113762e-05,
      "loss": 0.7238,
      "step": 4020
    },
    {
      "epoch": 1.091549295774648,
      "grad_norm": 0.8710939288139343,
      "learning_rate": 2.2758667388949082e-05,
      "loss": 0.5317,
      "step": 4030
    },
    {
      "epoch": 1.0942578548212352,
      "grad_norm": 1.2166188955307007,
      "learning_rate": 2.26909534127844e-05,
      "loss": 0.7411,
      "step": 4040
    },
    {
      "epoch": 1.0969664138678223,
      "grad_norm": 1.1195735931396484,
      "learning_rate": 2.2623239436619718e-05,
      "loss": 0.6038,
      "step": 4050
    },
    {
      "epoch": 1.0996749729144095,
      "grad_norm": 1.155215859413147,
      "learning_rate": 2.255552546045504e-05,
      "loss": 0.6588,
      "step": 4060
    },
    {
      "epoch": 1.1023835319609967,
      "grad_norm": 0.9724383354187012,
      "learning_rate": 2.2487811484290358e-05,
      "loss": 0.6954,
      "step": 4070
    },
    {
      "epoch": 1.1050920910075839,
      "grad_norm": 0.9779070019721985,
      "learning_rate": 2.2420097508125677e-05,
      "loss": 0.5255,
      "step": 4080
    },
    {
      "epoch": 1.1078006500541713,
      "grad_norm": 0.9649428725242615,
      "learning_rate": 2.2352383531960997e-05,
      "loss": 0.587,
      "step": 4090
    },
    {
      "epoch": 1.1105092091007585,
      "grad_norm": 1.5298606157302856,
      "learning_rate": 2.2284669555796317e-05,
      "loss": 0.5569,
      "step": 4100
    },
    {
      "epoch": 1.1132177681473456,
      "grad_norm": 0.8326969146728516,
      "learning_rate": 2.2216955579631637e-05,
      "loss": 0.4984,
      "step": 4110
    },
    {
      "epoch": 1.1159263271939328,
      "grad_norm": 0.9062517285346985,
      "learning_rate": 2.2149241603466956e-05,
      "loss": 0.6257,
      "step": 4120
    },
    {
      "epoch": 1.11863488624052,
      "grad_norm": 1.229236364364624,
      "learning_rate": 2.2081527627302276e-05,
      "loss": 0.506,
      "step": 4130
    },
    {
      "epoch": 1.1213434452871072,
      "grad_norm": 1.151031494140625,
      "learning_rate": 2.2013813651137596e-05,
      "loss": 0.5877,
      "step": 4140
    },
    {
      "epoch": 1.1240520043336946,
      "grad_norm": 1.0478211641311646,
      "learning_rate": 2.1946099674972916e-05,
      "loss": 0.5682,
      "step": 4150
    },
    {
      "epoch": 1.1267605633802817,
      "grad_norm": 1.0285446643829346,
      "learning_rate": 2.1878385698808235e-05,
      "loss": 0.5046,
      "step": 4160
    },
    {
      "epoch": 1.129469122426869,
      "grad_norm": 0.8580082058906555,
      "learning_rate": 2.1810671722643555e-05,
      "loss": 0.6101,
      "step": 4170
    },
    {
      "epoch": 1.132177681473456,
      "grad_norm": 1.129459261894226,
      "learning_rate": 2.174295774647887e-05,
      "loss": 0.6291,
      "step": 4180
    },
    {
      "epoch": 1.1348862405200433,
      "grad_norm": 0.9544103741645813,
      "learning_rate": 2.1675243770314195e-05,
      "loss": 0.6383,
      "step": 4190
    },
    {
      "epoch": 1.1375947995666307,
      "grad_norm": 1.0474711656570435,
      "learning_rate": 2.1607529794149515e-05,
      "loss": 0.5075,
      "step": 4200
    },
    {
      "epoch": 1.1403033586132179,
      "grad_norm": 0.9224100112915039,
      "learning_rate": 2.153981581798483e-05,
      "loss": 0.6163,
      "step": 4210
    },
    {
      "epoch": 1.143011917659805,
      "grad_norm": 1.3203338384628296,
      "learning_rate": 2.1472101841820154e-05,
      "loss": 0.5124,
      "step": 4220
    },
    {
      "epoch": 1.1457204767063922,
      "grad_norm": 1.5328575372695923,
      "learning_rate": 2.1404387865655474e-05,
      "loss": 0.5324,
      "step": 4230
    },
    {
      "epoch": 1.1484290357529794,
      "grad_norm": 1.1119916439056396,
      "learning_rate": 2.133667388949079e-05,
      "loss": 0.6102,
      "step": 4240
    },
    {
      "epoch": 1.1511375947995666,
      "grad_norm": 0.9391865134239197,
      "learning_rate": 2.126895991332611e-05,
      "loss": 0.6736,
      "step": 4250
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 1.092468500137329,
      "learning_rate": 2.1201245937161433e-05,
      "loss": 0.5788,
      "step": 4260
    },
    {
      "epoch": 1.1565547128927411,
      "grad_norm": 1.1076958179473877,
      "learning_rate": 2.113353196099675e-05,
      "loss": 0.5711,
      "step": 4270
    },
    {
      "epoch": 1.1592632719393283,
      "grad_norm": 1.0139601230621338,
      "learning_rate": 2.106581798483207e-05,
      "loss": 0.6242,
      "step": 4280
    },
    {
      "epoch": 1.1619718309859155,
      "grad_norm": 1.7790119647979736,
      "learning_rate": 2.0998104008667392e-05,
      "loss": 0.4516,
      "step": 4290
    },
    {
      "epoch": 1.1646803900325027,
      "grad_norm": 1.0027824640274048,
      "learning_rate": 2.093039003250271e-05,
      "loss": 0.5827,
      "step": 4300
    },
    {
      "epoch": 1.1673889490790899,
      "grad_norm": 1.2051992416381836,
      "learning_rate": 2.086267605633803e-05,
      "loss": 0.7388,
      "step": 4310
    },
    {
      "epoch": 1.1700975081256773,
      "grad_norm": 1.0644947290420532,
      "learning_rate": 2.0794962080173348e-05,
      "loss": 0.6412,
      "step": 4320
    },
    {
      "epoch": 1.1728060671722644,
      "grad_norm": 1.0996564626693726,
      "learning_rate": 2.0727248104008668e-05,
      "loss": 0.643,
      "step": 4330
    },
    {
      "epoch": 1.1755146262188516,
      "grad_norm": 0.7589508891105652,
      "learning_rate": 2.0659534127843988e-05,
      "loss": 0.4966,
      "step": 4340
    },
    {
      "epoch": 1.1782231852654388,
      "grad_norm": 0.9506021738052368,
      "learning_rate": 2.0591820151679308e-05,
      "loss": 0.7953,
      "step": 4350
    },
    {
      "epoch": 1.180931744312026,
      "grad_norm": 1.2147547006607056,
      "learning_rate": 2.0524106175514627e-05,
      "loss": 0.5847,
      "step": 4360
    },
    {
      "epoch": 1.1836403033586131,
      "grad_norm": 1.7149943113327026,
      "learning_rate": 2.0456392199349947e-05,
      "loss": 0.6843,
      "step": 4370
    },
    {
      "epoch": 1.1863488624052003,
      "grad_norm": 1.1301486492156982,
      "learning_rate": 2.0388678223185267e-05,
      "loss": 0.6359,
      "step": 4380
    },
    {
      "epoch": 1.1890574214517877,
      "grad_norm": 0.8953407406806946,
      "learning_rate": 2.0320964247020587e-05,
      "loss": 0.651,
      "step": 4390
    },
    {
      "epoch": 1.191765980498375,
      "grad_norm": 1.1681376695632935,
      "learning_rate": 2.0253250270855906e-05,
      "loss": 0.801,
      "step": 4400
    },
    {
      "epoch": 1.194474539544962,
      "grad_norm": 0.9446077942848206,
      "learning_rate": 2.0185536294691226e-05,
      "loss": 0.6156,
      "step": 4410
    },
    {
      "epoch": 1.1971830985915493,
      "grad_norm": 1.1220650672912598,
      "learning_rate": 2.0117822318526543e-05,
      "loss": 0.6587,
      "step": 4420
    },
    {
      "epoch": 1.1998916576381364,
      "grad_norm": 1.2905648946762085,
      "learning_rate": 2.0050108342361866e-05,
      "loss": 0.5575,
      "step": 4430
    },
    {
      "epoch": 1.2026002166847238,
      "grad_norm": 0.8649013638496399,
      "learning_rate": 1.9982394366197185e-05,
      "loss": 0.5531,
      "step": 4440
    },
    {
      "epoch": 1.205308775731311,
      "grad_norm": 0.9757486581802368,
      "learning_rate": 1.9914680390032502e-05,
      "loss": 0.5589,
      "step": 4450
    },
    {
      "epoch": 1.2080173347778982,
      "grad_norm": 1.015254259109497,
      "learning_rate": 1.9846966413867825e-05,
      "loss": 0.6477,
      "step": 4460
    },
    {
      "epoch": 1.2107258938244854,
      "grad_norm": 1.155834674835205,
      "learning_rate": 1.9779252437703145e-05,
      "loss": 0.7464,
      "step": 4470
    },
    {
      "epoch": 1.2134344528710725,
      "grad_norm": 1.0679597854614258,
      "learning_rate": 1.971153846153846e-05,
      "loss": 0.6491,
      "step": 4480
    },
    {
      "epoch": 1.2161430119176597,
      "grad_norm": 1.2810002565383911,
      "learning_rate": 1.964382448537378e-05,
      "loss": 0.7543,
      "step": 4490
    },
    {
      "epoch": 1.218851570964247,
      "grad_norm": 0.7941994667053223,
      "learning_rate": 1.9576110509209104e-05,
      "loss": 0.6032,
      "step": 4500
    },
    {
      "epoch": 1.2215601300108343,
      "grad_norm": 1.206900954246521,
      "learning_rate": 1.950839653304442e-05,
      "loss": 0.6462,
      "step": 4510
    },
    {
      "epoch": 1.2242686890574215,
      "grad_norm": 1.0450817346572876,
      "learning_rate": 1.944068255687974e-05,
      "loss": 0.5702,
      "step": 4520
    },
    {
      "epoch": 1.2269772481040087,
      "grad_norm": 1.0622614622116089,
      "learning_rate": 1.9372968580715063e-05,
      "loss": 0.6022,
      "step": 4530
    },
    {
      "epoch": 1.2296858071505958,
      "grad_norm": 0.8644142150878906,
      "learning_rate": 1.930525460455038e-05,
      "loss": 0.5274,
      "step": 4540
    },
    {
      "epoch": 1.232394366197183,
      "grad_norm": 1.3063981533050537,
      "learning_rate": 1.92375406283857e-05,
      "loss": 0.5957,
      "step": 4550
    },
    {
      "epoch": 1.2351029252437704,
      "grad_norm": 1.0433636903762817,
      "learning_rate": 1.916982665222102e-05,
      "loss": 0.5807,
      "step": 4560
    },
    {
      "epoch": 1.2378114842903576,
      "grad_norm": 0.9122921228408813,
      "learning_rate": 1.910211267605634e-05,
      "loss": 0.5852,
      "step": 4570
    },
    {
      "epoch": 1.2405200433369448,
      "grad_norm": 1.0502820014953613,
      "learning_rate": 1.903439869989166e-05,
      "loss": 0.7365,
      "step": 4580
    },
    {
      "epoch": 1.243228602383532,
      "grad_norm": 1.6880823373794556,
      "learning_rate": 1.8966684723726975e-05,
      "loss": 0.7494,
      "step": 4590
    },
    {
      "epoch": 1.2459371614301191,
      "grad_norm": 1.465762734413147,
      "learning_rate": 1.8898970747562298e-05,
      "loss": 0.5754,
      "step": 4600
    },
    {
      "epoch": 1.2486457204767063,
      "grad_norm": 0.9930922389030457,
      "learning_rate": 1.8831256771397618e-05,
      "loss": 0.669,
      "step": 4610
    },
    {
      "epoch": 1.2513542795232935,
      "grad_norm": 0.907328724861145,
      "learning_rate": 1.8763542795232934e-05,
      "loss": 0.6359,
      "step": 4620
    },
    {
      "epoch": 1.2540628385698809,
      "grad_norm": 1.13089120388031,
      "learning_rate": 1.8695828819068258e-05,
      "loss": 0.5314,
      "step": 4630
    },
    {
      "epoch": 1.256771397616468,
      "grad_norm": 0.9539127945899963,
      "learning_rate": 1.8628114842903577e-05,
      "loss": 0.6636,
      "step": 4640
    },
    {
      "epoch": 1.2594799566630552,
      "grad_norm": 1.2277448177337646,
      "learning_rate": 1.8560400866738894e-05,
      "loss": 0.7189,
      "step": 4650
    },
    {
      "epoch": 1.2621885157096424,
      "grad_norm": 0.9172330498695374,
      "learning_rate": 1.8492686890574213e-05,
      "loss": 0.7035,
      "step": 4660
    },
    {
      "epoch": 1.2648970747562296,
      "grad_norm": 1.1309260129928589,
      "learning_rate": 1.8424972914409537e-05,
      "loss": 0.6414,
      "step": 4670
    },
    {
      "epoch": 1.267605633802817,
      "grad_norm": 0.9458346962928772,
      "learning_rate": 1.8357258938244853e-05,
      "loss": 0.5331,
      "step": 4680
    },
    {
      "epoch": 1.2703141928494042,
      "grad_norm": 0.9745538830757141,
      "learning_rate": 1.8289544962080173e-05,
      "loss": 0.5988,
      "step": 4690
    },
    {
      "epoch": 1.2730227518959913,
      "grad_norm": 1.019284725189209,
      "learning_rate": 1.8221830985915496e-05,
      "loss": 0.608,
      "step": 4700
    },
    {
      "epoch": 1.2757313109425785,
      "grad_norm": 1.0616439580917358,
      "learning_rate": 1.8154117009750812e-05,
      "loss": 0.5897,
      "step": 4710
    },
    {
      "epoch": 1.2784398699891657,
      "grad_norm": 1.29050874710083,
      "learning_rate": 1.8086403033586132e-05,
      "loss": 0.5437,
      "step": 4720
    },
    {
      "epoch": 1.281148429035753,
      "grad_norm": 0.8948279619216919,
      "learning_rate": 1.8018689057421452e-05,
      "loss": 0.5895,
      "step": 4730
    },
    {
      "epoch": 1.2838569880823403,
      "grad_norm": 1.6363072395324707,
      "learning_rate": 1.795097508125677e-05,
      "loss": 0.6381,
      "step": 4740
    },
    {
      "epoch": 1.2865655471289275,
      "grad_norm": 1.193264126777649,
      "learning_rate": 1.788326110509209e-05,
      "loss": 0.6357,
      "step": 4750
    },
    {
      "epoch": 1.2892741061755146,
      "grad_norm": 1.1202083826065063,
      "learning_rate": 1.781554712892741e-05,
      "loss": 0.6572,
      "step": 4760
    },
    {
      "epoch": 1.2919826652221018,
      "grad_norm": 1.1248512268066406,
      "learning_rate": 1.774783315276273e-05,
      "loss": 0.4865,
      "step": 4770
    },
    {
      "epoch": 1.294691224268689,
      "grad_norm": 1.2802611589431763,
      "learning_rate": 1.768011917659805e-05,
      "loss": 0.689,
      "step": 4780
    },
    {
      "epoch": 1.2973997833152762,
      "grad_norm": 0.8354562520980835,
      "learning_rate": 1.761240520043337e-05,
      "loss": 0.6817,
      "step": 4790
    },
    {
      "epoch": 1.3001083423618636,
      "grad_norm": 1.7370377779006958,
      "learning_rate": 1.754469122426869e-05,
      "loss": 0.7163,
      "step": 4800
    },
    {
      "epoch": 1.3028169014084507,
      "grad_norm": 1.0256918668746948,
      "learning_rate": 1.747697724810401e-05,
      "loss": 0.6878,
      "step": 4810
    },
    {
      "epoch": 1.305525460455038,
      "grad_norm": 0.827785074710846,
      "learning_rate": 1.740926327193933e-05,
      "loss": 0.5694,
      "step": 4820
    },
    {
      "epoch": 1.308234019501625,
      "grad_norm": 1.1199796199798584,
      "learning_rate": 1.734154929577465e-05,
      "loss": 0.5966,
      "step": 4830
    },
    {
      "epoch": 1.3109425785482123,
      "grad_norm": 1.191920518875122,
      "learning_rate": 1.727383531960997e-05,
      "loss": 0.6269,
      "step": 4840
    },
    {
      "epoch": 1.3136511375947997,
      "grad_norm": 1.0422496795654297,
      "learning_rate": 1.720612134344529e-05,
      "loss": 0.5063,
      "step": 4850
    },
    {
      "epoch": 1.3163596966413869,
      "grad_norm": 1.1203612089157104,
      "learning_rate": 1.7138407367280605e-05,
      "loss": 0.6082,
      "step": 4860
    },
    {
      "epoch": 1.319068255687974,
      "grad_norm": 1.357377052307129,
      "learning_rate": 1.707069339111593e-05,
      "loss": 0.723,
      "step": 4870
    },
    {
      "epoch": 1.3217768147345612,
      "grad_norm": 0.9724227786064148,
      "learning_rate": 1.7002979414951248e-05,
      "loss": 0.6537,
      "step": 4880
    },
    {
      "epoch": 1.3244853737811484,
      "grad_norm": 0.8258758187294006,
      "learning_rate": 1.6935265438786565e-05,
      "loss": 0.5776,
      "step": 4890
    },
    {
      "epoch": 1.3271939328277356,
      "grad_norm": 0.9944698810577393,
      "learning_rate": 1.6867551462621888e-05,
      "loss": 0.6525,
      "step": 4900
    },
    {
      "epoch": 1.3299024918743227,
      "grad_norm": 1.0582298040390015,
      "learning_rate": 1.6799837486457208e-05,
      "loss": 0.6183,
      "step": 4910
    },
    {
      "epoch": 1.3326110509209101,
      "grad_norm": 1.0075491666793823,
      "learning_rate": 1.6732123510292524e-05,
      "loss": 0.6822,
      "step": 4920
    },
    {
      "epoch": 1.3353196099674973,
      "grad_norm": 1.0225409269332886,
      "learning_rate": 1.6664409534127844e-05,
      "loss": 0.647,
      "step": 4930
    },
    {
      "epoch": 1.3380281690140845,
      "grad_norm": 1.0878095626831055,
      "learning_rate": 1.6596695557963167e-05,
      "loss": 0.5228,
      "step": 4940
    },
    {
      "epoch": 1.3407367280606717,
      "grad_norm": 0.9857325553894043,
      "learning_rate": 1.6528981581798483e-05,
      "loss": 0.6077,
      "step": 4950
    },
    {
      "epoch": 1.3434452871072589,
      "grad_norm": 1.1044446229934692,
      "learning_rate": 1.6461267605633803e-05,
      "loss": 0.4907,
      "step": 4960
    },
    {
      "epoch": 1.3461538461538463,
      "grad_norm": 1.0676548480987549,
      "learning_rate": 1.6393553629469126e-05,
      "loss": 0.6041,
      "step": 4970
    },
    {
      "epoch": 1.3488624052004334,
      "grad_norm": 1.0534299612045288,
      "learning_rate": 1.6325839653304442e-05,
      "loss": 0.6009,
      "step": 4980
    },
    {
      "epoch": 1.3515709642470206,
      "grad_norm": 1.0179733037948608,
      "learning_rate": 1.6258125677139762e-05,
      "loss": 0.575,
      "step": 4990
    },
    {
      "epoch": 1.3542795232936078,
      "grad_norm": 1.1303061246871948,
      "learning_rate": 1.6190411700975082e-05,
      "loss": 0.5793,
      "step": 5000
    },
    {
      "epoch": 1.356988082340195,
      "grad_norm": 1.1414146423339844,
      "learning_rate": 1.6122697724810402e-05,
      "loss": 0.6076,
      "step": 5010
    },
    {
      "epoch": 1.3596966413867824,
      "grad_norm": 1.1882481575012207,
      "learning_rate": 1.605498374864572e-05,
      "loss": 0.6615,
      "step": 5020
    },
    {
      "epoch": 1.3624052004333693,
      "grad_norm": 1.3759840726852417,
      "learning_rate": 1.598726977248104e-05,
      "loss": 0.7059,
      "step": 5030
    },
    {
      "epoch": 1.3651137594799567,
      "grad_norm": 1.3565099239349365,
      "learning_rate": 1.591955579631636e-05,
      "loss": 0.7081,
      "step": 5040
    },
    {
      "epoch": 1.367822318526544,
      "grad_norm": 0.9575390219688416,
      "learning_rate": 1.585184182015168e-05,
      "loss": 0.5669,
      "step": 5050
    },
    {
      "epoch": 1.370530877573131,
      "grad_norm": 1.0564329624176025,
      "learning_rate": 1.5784127843986997e-05,
      "loss": 0.5828,
      "step": 5060
    },
    {
      "epoch": 1.3732394366197183,
      "grad_norm": 1.0665363073349,
      "learning_rate": 1.571641386782232e-05,
      "loss": 0.5629,
      "step": 5070
    },
    {
      "epoch": 1.3759479956663054,
      "grad_norm": 1.0482436418533325,
      "learning_rate": 1.564869989165764e-05,
      "loss": 0.6329,
      "step": 5080
    },
    {
      "epoch": 1.3786565547128928,
      "grad_norm": 1.0340741872787476,
      "learning_rate": 1.5580985915492956e-05,
      "loss": 0.7017,
      "step": 5090
    },
    {
      "epoch": 1.38136511375948,
      "grad_norm": 1.478851556777954,
      "learning_rate": 1.5513271939328276e-05,
      "loss": 0.5269,
      "step": 5100
    },
    {
      "epoch": 1.3840736728060672,
      "grad_norm": 1.1085318326950073,
      "learning_rate": 1.54455579631636e-05,
      "loss": 0.5917,
      "step": 5110
    },
    {
      "epoch": 1.3867822318526544,
      "grad_norm": 1.0779467821121216,
      "learning_rate": 1.5377843986998916e-05,
      "loss": 0.564,
      "step": 5120
    },
    {
      "epoch": 1.3894907908992415,
      "grad_norm": 1.0688434839248657,
      "learning_rate": 1.5310130010834236e-05,
      "loss": 0.6296,
      "step": 5130
    },
    {
      "epoch": 1.392199349945829,
      "grad_norm": 1.0654934644699097,
      "learning_rate": 1.5242416034669557e-05,
      "loss": 0.6966,
      "step": 5140
    },
    {
      "epoch": 1.394907908992416,
      "grad_norm": 0.8654406070709229,
      "learning_rate": 1.5174702058504875e-05,
      "loss": 0.6053,
      "step": 5150
    },
    {
      "epoch": 1.3976164680390033,
      "grad_norm": 1.3607966899871826,
      "learning_rate": 1.5106988082340195e-05,
      "loss": 0.68,
      "step": 5160
    },
    {
      "epoch": 1.4003250270855905,
      "grad_norm": 1.1225939989089966,
      "learning_rate": 1.5039274106175516e-05,
      "loss": 0.7324,
      "step": 5170
    },
    {
      "epoch": 1.4030335861321777,
      "grad_norm": 1.1524723768234253,
      "learning_rate": 1.4971560130010834e-05,
      "loss": 0.6015,
      "step": 5180
    },
    {
      "epoch": 1.4057421451787648,
      "grad_norm": 0.9087136387825012,
      "learning_rate": 1.4903846153846154e-05,
      "loss": 0.4963,
      "step": 5190
    },
    {
      "epoch": 1.408450704225352,
      "grad_norm": 0.9965050220489502,
      "learning_rate": 1.4836132177681476e-05,
      "loss": 0.619,
      "step": 5200
    },
    {
      "epoch": 1.4111592632719394,
      "grad_norm": 0.9387895464897156,
      "learning_rate": 1.4768418201516792e-05,
      "loss": 0.6321,
      "step": 5210
    },
    {
      "epoch": 1.4138678223185266,
      "grad_norm": 1.1080437898635864,
      "learning_rate": 1.4700704225352113e-05,
      "loss": 0.6798,
      "step": 5220
    },
    {
      "epoch": 1.4165763813651138,
      "grad_norm": 1.521795630455017,
      "learning_rate": 1.4632990249187433e-05,
      "loss": 0.6121,
      "step": 5230
    },
    {
      "epoch": 1.419284940411701,
      "grad_norm": 1.0103155374526978,
      "learning_rate": 1.4565276273022751e-05,
      "loss": 0.5616,
      "step": 5240
    },
    {
      "epoch": 1.4219934994582881,
      "grad_norm": 1.1197822093963623,
      "learning_rate": 1.4497562296858073e-05,
      "loss": 0.6529,
      "step": 5250
    },
    {
      "epoch": 1.4247020585048755,
      "grad_norm": 0.8853824734687805,
      "learning_rate": 1.4429848320693392e-05,
      "loss": 0.6673,
      "step": 5260
    },
    {
      "epoch": 1.4274106175514627,
      "grad_norm": 1.3472704887390137,
      "learning_rate": 1.436213434452871e-05,
      "loss": 0.6928,
      "step": 5270
    },
    {
      "epoch": 1.4301191765980499,
      "grad_norm": 1.0880874395370483,
      "learning_rate": 1.429442036836403e-05,
      "loss": 0.5393,
      "step": 5280
    },
    {
      "epoch": 1.432827735644637,
      "grad_norm": 1.2944179773330688,
      "learning_rate": 1.4226706392199352e-05,
      "loss": 0.6562,
      "step": 5290
    },
    {
      "epoch": 1.4355362946912242,
      "grad_norm": 1.022107481956482,
      "learning_rate": 1.415899241603467e-05,
      "loss": 0.594,
      "step": 5300
    },
    {
      "epoch": 1.4382448537378114,
      "grad_norm": 1.0733791589736938,
      "learning_rate": 1.409127843986999e-05,
      "loss": 0.7028,
      "step": 5310
    },
    {
      "epoch": 1.4409534127843986,
      "grad_norm": 0.8388900756835938,
      "learning_rate": 1.4023564463705311e-05,
      "loss": 0.6125,
      "step": 5320
    },
    {
      "epoch": 1.443661971830986,
      "grad_norm": 1.270707368850708,
      "learning_rate": 1.3955850487540627e-05,
      "loss": 0.6394,
      "step": 5330
    },
    {
      "epoch": 1.4463705308775732,
      "grad_norm": 0.991171658039093,
      "learning_rate": 1.3888136511375949e-05,
      "loss": 0.5061,
      "step": 5340
    },
    {
      "epoch": 1.4490790899241603,
      "grad_norm": 0.8342704176902771,
      "learning_rate": 1.3820422535211269e-05,
      "loss": 0.6053,
      "step": 5350
    },
    {
      "epoch": 1.4517876489707475,
      "grad_norm": 1.1226094961166382,
      "learning_rate": 1.3752708559046587e-05,
      "loss": 0.5522,
      "step": 5360
    },
    {
      "epoch": 1.4544962080173347,
      "grad_norm": 0.8353278636932373,
      "learning_rate": 1.3684994582881908e-05,
      "loss": 0.6004,
      "step": 5370
    },
    {
      "epoch": 1.457204767063922,
      "grad_norm": 1.1049591302871704,
      "learning_rate": 1.3617280606717228e-05,
      "loss": 0.6223,
      "step": 5380
    },
    {
      "epoch": 1.4599133261105093,
      "grad_norm": 1.021132469177246,
      "learning_rate": 1.3549566630552546e-05,
      "loss": 0.6288,
      "step": 5390
    },
    {
      "epoch": 1.4626218851570965,
      "grad_norm": 1.1276899576187134,
      "learning_rate": 1.3481852654387866e-05,
      "loss": 0.5249,
      "step": 5400
    },
    {
      "epoch": 1.4653304442036836,
      "grad_norm": 1.2945473194122314,
      "learning_rate": 1.3414138678223187e-05,
      "loss": 0.6759,
      "step": 5410
    },
    {
      "epoch": 1.4680390032502708,
      "grad_norm": 1.240399956703186,
      "learning_rate": 1.3346424702058505e-05,
      "loss": 0.5075,
      "step": 5420
    },
    {
      "epoch": 1.470747562296858,
      "grad_norm": 1.1636488437652588,
      "learning_rate": 1.3278710725893825e-05,
      "loss": 0.4733,
      "step": 5430
    },
    {
      "epoch": 1.4734561213434452,
      "grad_norm": 0.90621018409729,
      "learning_rate": 1.3210996749729146e-05,
      "loss": 0.5656,
      "step": 5440
    },
    {
      "epoch": 1.4761646803900326,
      "grad_norm": 1.0093780755996704,
      "learning_rate": 1.3143282773564463e-05,
      "loss": 0.6956,
      "step": 5450
    },
    {
      "epoch": 1.4788732394366197,
      "grad_norm": 1.637175440788269,
      "learning_rate": 1.3075568797399784e-05,
      "loss": 0.5235,
      "step": 5460
    },
    {
      "epoch": 1.481581798483207,
      "grad_norm": 1.0978059768676758,
      "learning_rate": 1.3007854821235104e-05,
      "loss": 0.5957,
      "step": 5470
    },
    {
      "epoch": 1.484290357529794,
      "grad_norm": 1.2301384210586548,
      "learning_rate": 1.2940140845070422e-05,
      "loss": 0.6025,
      "step": 5480
    },
    {
      "epoch": 1.4869989165763813,
      "grad_norm": 0.985997200012207,
      "learning_rate": 1.2872426868905744e-05,
      "loss": 0.6979,
      "step": 5490
    },
    {
      "epoch": 1.4897074756229687,
      "grad_norm": 0.9522268176078796,
      "learning_rate": 1.2804712892741063e-05,
      "loss": 0.6123,
      "step": 5500
    },
    {
      "epoch": 1.4924160346695559,
      "grad_norm": 0.7833475470542908,
      "learning_rate": 1.2736998916576381e-05,
      "loss": 0.5138,
      "step": 5510
    },
    {
      "epoch": 1.495124593716143,
      "grad_norm": 1.0668914318084717,
      "learning_rate": 1.2669284940411701e-05,
      "loss": 0.5498,
      "step": 5520
    },
    {
      "epoch": 1.4978331527627302,
      "grad_norm": 1.2160781621932983,
      "learning_rate": 1.2601570964247023e-05,
      "loss": 0.5883,
      "step": 5530
    },
    {
      "epoch": 1.5005417118093174,
      "grad_norm": 0.8564692735671997,
      "learning_rate": 1.253385698808234e-05,
      "loss": 0.6798,
      "step": 5540
    },
    {
      "epoch": 1.5032502708559048,
      "grad_norm": 1.017398476600647,
      "learning_rate": 1.246614301191766e-05,
      "loss": 0.5423,
      "step": 5550
    },
    {
      "epoch": 1.5059588299024917,
      "grad_norm": 1.1124420166015625,
      "learning_rate": 1.239842903575298e-05,
      "loss": 0.6028,
      "step": 5560
    },
    {
      "epoch": 1.5086673889490791,
      "grad_norm": 0.944046139717102,
      "learning_rate": 1.23307150595883e-05,
      "loss": 0.7357,
      "step": 5570
    },
    {
      "epoch": 1.5113759479956663,
      "grad_norm": 0.8816554546356201,
      "learning_rate": 1.226300108342362e-05,
      "loss": 0.5653,
      "step": 5580
    },
    {
      "epoch": 1.5140845070422535,
      "grad_norm": 1.0475850105285645,
      "learning_rate": 1.219528710725894e-05,
      "loss": 0.6753,
      "step": 5590
    },
    {
      "epoch": 1.516793066088841,
      "grad_norm": 0.9839484691619873,
      "learning_rate": 1.2127573131094258e-05,
      "loss": 0.5696,
      "step": 5600
    },
    {
      "epoch": 1.5195016251354279,
      "grad_norm": 1.1691083908081055,
      "learning_rate": 1.2059859154929579e-05,
      "loss": 0.5522,
      "step": 5610
    },
    {
      "epoch": 1.5222101841820153,
      "grad_norm": 1.1366808414459229,
      "learning_rate": 1.1992145178764897e-05,
      "loss": 0.5952,
      "step": 5620
    },
    {
      "epoch": 1.5249187432286024,
      "grad_norm": 1.287482500076294,
      "learning_rate": 1.1924431202600217e-05,
      "loss": 0.6126,
      "step": 5630
    },
    {
      "epoch": 1.5276273022751896,
      "grad_norm": 0.9682525396347046,
      "learning_rate": 1.1856717226435538e-05,
      "loss": 0.6273,
      "step": 5640
    },
    {
      "epoch": 1.5303358613217768,
      "grad_norm": 1.1658917665481567,
      "learning_rate": 1.1789003250270856e-05,
      "loss": 0.5507,
      "step": 5650
    },
    {
      "epoch": 1.533044420368364,
      "grad_norm": 0.9726844429969788,
      "learning_rate": 1.1721289274106176e-05,
      "loss": 0.5416,
      "step": 5660
    },
    {
      "epoch": 1.5357529794149514,
      "grad_norm": 1.0281214714050293,
      "learning_rate": 1.1653575297941494e-05,
      "loss": 0.6863,
      "step": 5670
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.8560875058174133,
      "learning_rate": 1.1585861321776816e-05,
      "loss": 0.5847,
      "step": 5680
    },
    {
      "epoch": 1.5411700975081257,
      "grad_norm": 1.051383376121521,
      "learning_rate": 1.1518147345612135e-05,
      "loss": 0.6444,
      "step": 5690
    },
    {
      "epoch": 1.543878656554713,
      "grad_norm": 1.7500959634780884,
      "learning_rate": 1.1450433369447454e-05,
      "loss": 0.6473,
      "step": 5700
    },
    {
      "epoch": 1.5465872156013,
      "grad_norm": 0.978952169418335,
      "learning_rate": 1.1382719393282775e-05,
      "loss": 0.5935,
      "step": 5710
    },
    {
      "epoch": 1.5492957746478875,
      "grad_norm": 1.1047412157058716,
      "learning_rate": 1.1315005417118093e-05,
      "loss": 0.6452,
      "step": 5720
    },
    {
      "epoch": 1.5520043336944744,
      "grad_norm": 0.8608065843582153,
      "learning_rate": 1.1247291440953413e-05,
      "loss": 0.536,
      "step": 5730
    },
    {
      "epoch": 1.5547128927410618,
      "grad_norm": 0.9491072297096252,
      "learning_rate": 1.1179577464788733e-05,
      "loss": 0.5688,
      "step": 5740
    },
    {
      "epoch": 1.557421451787649,
      "grad_norm": 0.9023319482803345,
      "learning_rate": 1.1111863488624052e-05,
      "loss": 0.535,
      "step": 5750
    },
    {
      "epoch": 1.5601300108342362,
      "grad_norm": 1.153150200843811,
      "learning_rate": 1.1044149512459372e-05,
      "loss": 0.6865,
      "step": 5760
    },
    {
      "epoch": 1.5628385698808234,
      "grad_norm": 1.136001706123352,
      "learning_rate": 1.0976435536294692e-05,
      "loss": 0.6111,
      "step": 5770
    },
    {
      "epoch": 1.5655471289274105,
      "grad_norm": 1.1139671802520752,
      "learning_rate": 1.0908721560130012e-05,
      "loss": 0.6191,
      "step": 5780
    },
    {
      "epoch": 1.568255687973998,
      "grad_norm": 1.0307940244674683,
      "learning_rate": 1.084100758396533e-05,
      "loss": 0.5559,
      "step": 5790
    },
    {
      "epoch": 1.570964247020585,
      "grad_norm": 1.246856689453125,
      "learning_rate": 1.0773293607800651e-05,
      "loss": 0.6949,
      "step": 5800
    },
    {
      "epoch": 1.5736728060671723,
      "grad_norm": 1.1508549451828003,
      "learning_rate": 1.0705579631635971e-05,
      "loss": 0.6288,
      "step": 5810
    },
    {
      "epoch": 1.5763813651137595,
      "grad_norm": 0.7929187417030334,
      "learning_rate": 1.0637865655471289e-05,
      "loss": 0.5678,
      "step": 5820
    },
    {
      "epoch": 1.5790899241603467,
      "grad_norm": 0.8414401412010193,
      "learning_rate": 1.057015167930661e-05,
      "loss": 0.577,
      "step": 5830
    },
    {
      "epoch": 1.581798483206934,
      "grad_norm": 0.9435910582542419,
      "learning_rate": 1.0502437703141929e-05,
      "loss": 0.6068,
      "step": 5840
    },
    {
      "epoch": 1.584507042253521,
      "grad_norm": 1.2101738452911377,
      "learning_rate": 1.0434723726977248e-05,
      "loss": 0.5472,
      "step": 5850
    },
    {
      "epoch": 1.5872156013001084,
      "grad_norm": 1.1350573301315308,
      "learning_rate": 1.0367009750812568e-05,
      "loss": 0.628,
      "step": 5860
    },
    {
      "epoch": 1.5899241603466956,
      "grad_norm": 0.9385409355163574,
      "learning_rate": 1.0299295774647888e-05,
      "loss": 0.4568,
      "step": 5870
    },
    {
      "epoch": 1.5926327193932828,
      "grad_norm": 1.2731642723083496,
      "learning_rate": 1.0231581798483208e-05,
      "loss": 0.6786,
      "step": 5880
    },
    {
      "epoch": 1.59534127843987,
      "grad_norm": 1.3831313848495483,
      "learning_rate": 1.0163867822318527e-05,
      "loss": 0.5168,
      "step": 5890
    },
    {
      "epoch": 1.5980498374864571,
      "grad_norm": 1.0612664222717285,
      "learning_rate": 1.0096153846153847e-05,
      "loss": 0.6313,
      "step": 5900
    },
    {
      "epoch": 1.6007583965330445,
      "grad_norm": 1.17173433303833,
      "learning_rate": 1.0028439869989167e-05,
      "loss": 0.6527,
      "step": 5910
    },
    {
      "epoch": 1.6034669555796315,
      "grad_norm": 0.8828514218330383,
      "learning_rate": 9.960725893824485e-06,
      "loss": 0.578,
      "step": 5920
    },
    {
      "epoch": 1.6061755146262189,
      "grad_norm": 1.1896041631698608,
      "learning_rate": 9.893011917659806e-06,
      "loss": 0.5881,
      "step": 5930
    },
    {
      "epoch": 1.608884073672806,
      "grad_norm": 1.151319980621338,
      "learning_rate": 9.825297941495124e-06,
      "loss": 0.6577,
      "step": 5940
    },
    {
      "epoch": 1.6115926327193932,
      "grad_norm": 1.1702347993850708,
      "learning_rate": 9.757583965330444e-06,
      "loss": 0.6544,
      "step": 5950
    },
    {
      "epoch": 1.6143011917659806,
      "grad_norm": 1.4820393323898315,
      "learning_rate": 9.689869989165764e-06,
      "loss": 0.6458,
      "step": 5960
    },
    {
      "epoch": 1.6170097508125676,
      "grad_norm": 0.9276593327522278,
      "learning_rate": 9.622156013001084e-06,
      "loss": 0.5032,
      "step": 5970
    },
    {
      "epoch": 1.619718309859155,
      "grad_norm": 1.014211654663086,
      "learning_rate": 9.554442036836404e-06,
      "loss": 0.5847,
      "step": 5980
    },
    {
      "epoch": 1.6224268689057422,
      "grad_norm": 1.117911696434021,
      "learning_rate": 9.486728060671723e-06,
      "loss": 0.6512,
      "step": 5990
    },
    {
      "epoch": 1.6251354279523293,
      "grad_norm": 1.0237858295440674,
      "learning_rate": 9.419014084507043e-06,
      "loss": 0.5976,
      "step": 6000
    },
    {
      "epoch": 1.6278439869989165,
      "grad_norm": 1.0489501953125,
      "learning_rate": 9.351300108342361e-06,
      "loss": 0.5692,
      "step": 6010
    },
    {
      "epoch": 1.6305525460455037,
      "grad_norm": 1.5277084112167358,
      "learning_rate": 9.283586132177683e-06,
      "loss": 0.7191,
      "step": 6020
    },
    {
      "epoch": 1.633261105092091,
      "grad_norm": 1.0909138917922974,
      "learning_rate": 9.215872156013002e-06,
      "loss": 0.6958,
      "step": 6030
    },
    {
      "epoch": 1.635969664138678,
      "grad_norm": 1.0283664464950562,
      "learning_rate": 9.14815817984832e-06,
      "loss": 0.7817,
      "step": 6040
    },
    {
      "epoch": 1.6386782231852655,
      "grad_norm": 1.1107125282287598,
      "learning_rate": 9.080444203683642e-06,
      "loss": 0.6758,
      "step": 6050
    },
    {
      "epoch": 1.6413867822318526,
      "grad_norm": 0.9428337812423706,
      "learning_rate": 9.01273022751896e-06,
      "loss": 0.6349,
      "step": 6060
    },
    {
      "epoch": 1.6440953412784398,
      "grad_norm": 0.9850417375564575,
      "learning_rate": 8.94501625135428e-06,
      "loss": 0.6216,
      "step": 6070
    },
    {
      "epoch": 1.6468039003250272,
      "grad_norm": 1.6595898866653442,
      "learning_rate": 8.8773022751896e-06,
      "loss": 0.6197,
      "step": 6080
    },
    {
      "epoch": 1.6495124593716142,
      "grad_norm": 0.9882603883743286,
      "learning_rate": 8.80958829902492e-06,
      "loss": 0.6761,
      "step": 6090
    },
    {
      "epoch": 1.6522210184182016,
      "grad_norm": 0.8669313788414001,
      "learning_rate": 8.741874322860239e-06,
      "loss": 0.6128,
      "step": 6100
    },
    {
      "epoch": 1.6549295774647887,
      "grad_norm": 1.3093326091766357,
      "learning_rate": 8.674160346695559e-06,
      "loss": 0.5486,
      "step": 6110
    },
    {
      "epoch": 1.657638136511376,
      "grad_norm": 1.1206177473068237,
      "learning_rate": 8.606446370530878e-06,
      "loss": 0.6745,
      "step": 6120
    },
    {
      "epoch": 1.6603466955579633,
      "grad_norm": 1.3651221990585327,
      "learning_rate": 8.538732394366197e-06,
      "loss": 0.6,
      "step": 6130
    },
    {
      "epoch": 1.6630552546045503,
      "grad_norm": 0.9890406727790833,
      "learning_rate": 8.471018418201518e-06,
      "loss": 0.5127,
      "step": 6140
    },
    {
      "epoch": 1.6657638136511377,
      "grad_norm": 1.0315097570419312,
      "learning_rate": 8.403304442036838e-06,
      "loss": 0.603,
      "step": 6150
    },
    {
      "epoch": 1.6684723726977249,
      "grad_norm": 1.3177698850631714,
      "learning_rate": 8.335590465872156e-06,
      "loss": 0.5952,
      "step": 6160
    },
    {
      "epoch": 1.671180931744312,
      "grad_norm": 1.0359762907028198,
      "learning_rate": 8.267876489707476e-06,
      "loss": 0.5727,
      "step": 6170
    },
    {
      "epoch": 1.6738894907908992,
      "grad_norm": 1.3185386657714844,
      "learning_rate": 8.200162513542795e-06,
      "loss": 0.5496,
      "step": 6180
    },
    {
      "epoch": 1.6765980498374864,
      "grad_norm": 1.0287071466445923,
      "learning_rate": 8.132448537378115e-06,
      "loss": 0.5922,
      "step": 6190
    },
    {
      "epoch": 1.6793066088840738,
      "grad_norm": 1.0958486795425415,
      "learning_rate": 8.064734561213435e-06,
      "loss": 0.6565,
      "step": 6200
    },
    {
      "epoch": 1.6820151679306607,
      "grad_norm": 1.1002994775772095,
      "learning_rate": 7.997020585048755e-06,
      "loss": 0.5729,
      "step": 6210
    },
    {
      "epoch": 1.6847237269772481,
      "grad_norm": 1.1458567380905151,
      "learning_rate": 7.929306608884074e-06,
      "loss": 0.6156,
      "step": 6220
    },
    {
      "epoch": 1.6874322860238353,
      "grad_norm": 1.3085635900497437,
      "learning_rate": 7.861592632719392e-06,
      "loss": 0.6151,
      "step": 6230
    },
    {
      "epoch": 1.6901408450704225,
      "grad_norm": 0.7770749926567078,
      "learning_rate": 7.793878656554714e-06,
      "loss": 0.7122,
      "step": 6240
    },
    {
      "epoch": 1.69284940411701,
      "grad_norm": 1.0399059057235718,
      "learning_rate": 7.726164680390032e-06,
      "loss": 0.7064,
      "step": 6250
    },
    {
      "epoch": 1.6955579631635969,
      "grad_norm": 0.880275309085846,
      "learning_rate": 7.658450704225352e-06,
      "loss": 0.5183,
      "step": 6260
    },
    {
      "epoch": 1.6982665222101843,
      "grad_norm": 0.9962217211723328,
      "learning_rate": 7.590736728060672e-06,
      "loss": 0.5028,
      "step": 6270
    },
    {
      "epoch": 1.7009750812567714,
      "grad_norm": 1.152593970298767,
      "learning_rate": 7.523022751895991e-06,
      "loss": 0.4956,
      "step": 6280
    },
    {
      "epoch": 1.7036836403033586,
      "grad_norm": 1.2241489887237549,
      "learning_rate": 7.455308775731311e-06,
      "loss": 0.6863,
      "step": 6290
    },
    {
      "epoch": 1.7063921993499458,
      "grad_norm": 0.8776826858520508,
      "learning_rate": 7.387594799566632e-06,
      "loss": 0.4814,
      "step": 6300
    },
    {
      "epoch": 1.709100758396533,
      "grad_norm": 0.8611180782318115,
      "learning_rate": 7.319880823401951e-06,
      "loss": 0.6647,
      "step": 6310
    },
    {
      "epoch": 1.7118093174431204,
      "grad_norm": 1.064143419265747,
      "learning_rate": 7.2521668472372695e-06,
      "loss": 0.6558,
      "step": 6320
    },
    {
      "epoch": 1.7145178764897073,
      "grad_norm": 1.2056905031204224,
      "learning_rate": 7.18445287107259e-06,
      "loss": 0.6738,
      "step": 6330
    },
    {
      "epoch": 1.7172264355362947,
      "grad_norm": 1.0999197959899902,
      "learning_rate": 7.11673889490791e-06,
      "loss": 0.4904,
      "step": 6340
    },
    {
      "epoch": 1.719934994582882,
      "grad_norm": 0.974844217300415,
      "learning_rate": 7.049024918743229e-06,
      "loss": 0.7024,
      "step": 6350
    },
    {
      "epoch": 1.722643553629469,
      "grad_norm": 0.8771654963493347,
      "learning_rate": 6.981310942578549e-06,
      "loss": 0.5946,
      "step": 6360
    },
    {
      "epoch": 1.7253521126760565,
      "grad_norm": 0.8247067928314209,
      "learning_rate": 6.913596966413868e-06,
      "loss": 0.5066,
      "step": 6370
    },
    {
      "epoch": 1.7280606717226434,
      "grad_norm": 1.181708812713623,
      "learning_rate": 6.845882990249187e-06,
      "loss": 0.5595,
      "step": 6380
    },
    {
      "epoch": 1.7307692307692308,
      "grad_norm": 1.0102592706680298,
      "learning_rate": 6.778169014084508e-06,
      "loss": 0.4813,
      "step": 6390
    },
    {
      "epoch": 1.733477789815818,
      "grad_norm": 1.3386262655258179,
      "learning_rate": 6.710455037919828e-06,
      "loss": 0.5012,
      "step": 6400
    },
    {
      "epoch": 1.7361863488624052,
      "grad_norm": 0.8875300288200378,
      "learning_rate": 6.6427410617551465e-06,
      "loss": 0.6478,
      "step": 6410
    },
    {
      "epoch": 1.7388949079089924,
      "grad_norm": 0.7200632691383362,
      "learning_rate": 6.5750270855904654e-06,
      "loss": 0.5162,
      "step": 6420
    },
    {
      "epoch": 1.7416034669555795,
      "grad_norm": 1.5699737071990967,
      "learning_rate": 6.507313109425786e-06,
      "loss": 0.6386,
      "step": 6430
    },
    {
      "epoch": 1.744312026002167,
      "grad_norm": 0.8368182182312012,
      "learning_rate": 6.439599133261105e-06,
      "loss": 0.6248,
      "step": 6440
    },
    {
      "epoch": 1.747020585048754,
      "grad_norm": 1.188996434211731,
      "learning_rate": 6.371885157096425e-06,
      "loss": 0.5661,
      "step": 6450
    },
    {
      "epoch": 1.7497291440953413,
      "grad_norm": 0.8680900931358337,
      "learning_rate": 6.304171180931745e-06,
      "loss": 0.5561,
      "step": 6460
    },
    {
      "epoch": 1.7524377031419285,
      "grad_norm": 1.215987205505371,
      "learning_rate": 6.236457204767064e-06,
      "loss": 0.7087,
      "step": 6470
    },
    {
      "epoch": 1.7551462621885157,
      "grad_norm": 0.8510155081748962,
      "learning_rate": 6.168743228602384e-06,
      "loss": 0.5354,
      "step": 6480
    },
    {
      "epoch": 1.757854821235103,
      "grad_norm": 1.1319353580474854,
      "learning_rate": 6.101029252437703e-06,
      "loss": 0.6295,
      "step": 6490
    },
    {
      "epoch": 1.76056338028169,
      "grad_norm": 0.8488337397575378,
      "learning_rate": 6.033315276273023e-06,
      "loss": 0.5814,
      "step": 6500
    },
    {
      "epoch": 1.7632719393282774,
      "grad_norm": 0.9687547087669373,
      "learning_rate": 5.9656013001083425e-06,
      "loss": 0.5945,
      "step": 6510
    },
    {
      "epoch": 1.7659804983748646,
      "grad_norm": 0.907223641872406,
      "learning_rate": 5.897887323943662e-06,
      "loss": 0.6217,
      "step": 6520
    },
    {
      "epoch": 1.7686890574214518,
      "grad_norm": 1.1729323863983154,
      "learning_rate": 5.830173347778982e-06,
      "loss": 0.5525,
      "step": 6530
    },
    {
      "epoch": 1.771397616468039,
      "grad_norm": 1.1760764122009277,
      "learning_rate": 5.762459371614302e-06,
      "loss": 0.557,
      "step": 6540
    },
    {
      "epoch": 1.7741061755146261,
      "grad_norm": 1.31881582736969,
      "learning_rate": 5.694745395449621e-06,
      "loss": 0.6603,
      "step": 6550
    },
    {
      "epoch": 1.7768147345612135,
      "grad_norm": 1.0937964916229248,
      "learning_rate": 5.62703141928494e-06,
      "loss": 0.7256,
      "step": 6560
    },
    {
      "epoch": 1.7795232936078007,
      "grad_norm": 1.3062313795089722,
      "learning_rate": 5.559317443120261e-06,
      "loss": 0.5044,
      "step": 6570
    },
    {
      "epoch": 1.7822318526543879,
      "grad_norm": 1.1317133903503418,
      "learning_rate": 5.49160346695558e-06,
      "loss": 0.7502,
      "step": 6580
    },
    {
      "epoch": 1.784940411700975,
      "grad_norm": 0.9742310047149658,
      "learning_rate": 5.4238894907909e-06,
      "loss": 0.5805,
      "step": 6590
    },
    {
      "epoch": 1.7876489707475622,
      "grad_norm": 0.9777428507804871,
      "learning_rate": 5.356175514626219e-06,
      "loss": 0.4625,
      "step": 6600
    },
    {
      "epoch": 1.7903575297941496,
      "grad_norm": 1.2376776933670044,
      "learning_rate": 5.288461538461538e-06,
      "loss": 0.6162,
      "step": 6610
    },
    {
      "epoch": 1.7930660888407366,
      "grad_norm": 1.1900907754898071,
      "learning_rate": 5.220747562296858e-06,
      "loss": 0.6356,
      "step": 6620
    },
    {
      "epoch": 1.795774647887324,
      "grad_norm": 0.8533565402030945,
      "learning_rate": 5.153033586132178e-06,
      "loss": 0.6233,
      "step": 6630
    },
    {
      "epoch": 1.7984832069339112,
      "grad_norm": 0.9886109232902527,
      "learning_rate": 5.085319609967498e-06,
      "loss": 0.66,
      "step": 6640
    },
    {
      "epoch": 1.8011917659804983,
      "grad_norm": 1.5471646785736084,
      "learning_rate": 5.0176056338028174e-06,
      "loss": 0.7324,
      "step": 6650
    },
    {
      "epoch": 1.8039003250270857,
      "grad_norm": 0.8524327278137207,
      "learning_rate": 4.949891657638136e-06,
      "loss": 0.5032,
      "step": 6660
    },
    {
      "epoch": 1.8066088840736727,
      "grad_norm": 1.0060397386550903,
      "learning_rate": 4.882177681473456e-06,
      "loss": 0.57,
      "step": 6670
    },
    {
      "epoch": 1.80931744312026,
      "grad_norm": 0.987137496471405,
      "learning_rate": 4.814463705308776e-06,
      "loss": 0.5067,
      "step": 6680
    },
    {
      "epoch": 1.8120260021668473,
      "grad_norm": 1.0408985614776611,
      "learning_rate": 4.746749729144096e-06,
      "loss": 0.6438,
      "step": 6690
    },
    {
      "epoch": 1.8147345612134345,
      "grad_norm": 1.102134108543396,
      "learning_rate": 4.679035752979415e-06,
      "loss": 0.6857,
      "step": 6700
    },
    {
      "epoch": 1.8174431202600216,
      "grad_norm": 1.1813561916351318,
      "learning_rate": 4.611321776814734e-06,
      "loss": 0.8046,
      "step": 6710
    },
    {
      "epoch": 1.8201516793066088,
      "grad_norm": 0.9800653457641602,
      "learning_rate": 4.543607800650054e-06,
      "loss": 0.5175,
      "step": 6720
    },
    {
      "epoch": 1.8228602383531962,
      "grad_norm": 0.9992241859436035,
      "learning_rate": 4.475893824485374e-06,
      "loss": 0.4868,
      "step": 6730
    },
    {
      "epoch": 1.8255687973997832,
      "grad_norm": 1.0839406251907349,
      "learning_rate": 4.408179848320694e-06,
      "loss": 0.6053,
      "step": 6740
    },
    {
      "epoch": 1.8282773564463706,
      "grad_norm": 2.062940835952759,
      "learning_rate": 4.340465872156013e-06,
      "loss": 0.6457,
      "step": 6750
    },
    {
      "epoch": 1.8309859154929577,
      "grad_norm": 1.1036698818206787,
      "learning_rate": 4.272751895991333e-06,
      "loss": 0.6643,
      "step": 6760
    },
    {
      "epoch": 1.833694474539545,
      "grad_norm": 1.5395054817199707,
      "learning_rate": 4.205037919826652e-06,
      "loss": 0.52,
      "step": 6770
    },
    {
      "epoch": 1.8364030335861323,
      "grad_norm": 0.9863872528076172,
      "learning_rate": 4.137323943661972e-06,
      "loss": 0.5817,
      "step": 6780
    },
    {
      "epoch": 1.8391115926327193,
      "grad_norm": 1.0013914108276367,
      "learning_rate": 4.069609967497292e-06,
      "loss": 0.5672,
      "step": 6790
    },
    {
      "epoch": 1.8418201516793067,
      "grad_norm": 1.1856735944747925,
      "learning_rate": 4.001895991332611e-06,
      "loss": 0.5415,
      "step": 6800
    },
    {
      "epoch": 1.8445287107258939,
      "grad_norm": 1.1431626081466675,
      "learning_rate": 3.934182015167931e-06,
      "loss": 0.5544,
      "step": 6810
    },
    {
      "epoch": 1.847237269772481,
      "grad_norm": 1.330095648765564,
      "learning_rate": 3.866468039003251e-06,
      "loss": 0.6802,
      "step": 6820
    },
    {
      "epoch": 1.8499458288190682,
      "grad_norm": 1.215237021446228,
      "learning_rate": 3.7987540628385698e-06,
      "loss": 0.5902,
      "step": 6830
    },
    {
      "epoch": 1.8526543878656554,
      "grad_norm": 0.9838855266571045,
      "learning_rate": 3.73104008667389e-06,
      "loss": 0.5597,
      "step": 6840
    },
    {
      "epoch": 1.8553629469122428,
      "grad_norm": 1.7073038816452026,
      "learning_rate": 3.663326110509209e-06,
      "loss": 0.5022,
      "step": 6850
    },
    {
      "epoch": 1.8580715059588297,
      "grad_norm": 1.1385856866836548,
      "learning_rate": 3.5956121343445286e-06,
      "loss": 0.6313,
      "step": 6860
    },
    {
      "epoch": 1.8607800650054171,
      "grad_norm": 0.825184166431427,
      "learning_rate": 3.527898158179849e-06,
      "loss": 0.5848,
      "step": 6870
    },
    {
      "epoch": 1.8634886240520043,
      "grad_norm": 0.8072906136512756,
      "learning_rate": 3.4601841820151677e-06,
      "loss": 0.6032,
      "step": 6880
    },
    {
      "epoch": 1.8661971830985915,
      "grad_norm": 0.8355621695518494,
      "learning_rate": 3.3924702058504875e-06,
      "loss": 0.6177,
      "step": 6890
    },
    {
      "epoch": 1.868905742145179,
      "grad_norm": 1.044012427330017,
      "learning_rate": 3.3247562296858077e-06,
      "loss": 0.5815,
      "step": 6900
    },
    {
      "epoch": 1.8716143011917659,
      "grad_norm": 1.1668286323547363,
      "learning_rate": 3.2570422535211266e-06,
      "loss": 0.6304,
      "step": 6910
    },
    {
      "epoch": 1.8743228602383533,
      "grad_norm": 0.9763556718826294,
      "learning_rate": 3.189328277356447e-06,
      "loss": 0.7288,
      "step": 6920
    },
    {
      "epoch": 1.8770314192849404,
      "grad_norm": 0.8994330763816833,
      "learning_rate": 3.121614301191766e-06,
      "loss": 0.6303,
      "step": 6930
    },
    {
      "epoch": 1.8797399783315276,
      "grad_norm": 0.998069167137146,
      "learning_rate": 3.0539003250270855e-06,
      "loss": 0.7017,
      "step": 6940
    },
    {
      "epoch": 1.8824485373781148,
      "grad_norm": 1.2133240699768066,
      "learning_rate": 2.9861863488624057e-06,
      "loss": 0.7055,
      "step": 6950
    },
    {
      "epoch": 1.885157096424702,
      "grad_norm": 1.1547271013259888,
      "learning_rate": 2.918472372697725e-06,
      "loss": 0.7105,
      "step": 6960
    },
    {
      "epoch": 1.8878656554712894,
      "grad_norm": 1.229193925857544,
      "learning_rate": 2.8507583965330443e-06,
      "loss": 0.5405,
      "step": 6970
    },
    {
      "epoch": 1.8905742145178763,
      "grad_norm": 0.8016520142555237,
      "learning_rate": 2.783044420368364e-06,
      "loss": 0.5708,
      "step": 6980
    },
    {
      "epoch": 1.8932827735644637,
      "grad_norm": 0.987113356590271,
      "learning_rate": 2.715330444203684e-06,
      "loss": 0.5433,
      "step": 6990
    },
    {
      "epoch": 1.895991332611051,
      "grad_norm": 1.451479196548462,
      "learning_rate": 2.647616468039003e-06,
      "loss": 0.556,
      "step": 7000
    },
    {
      "epoch": 1.898699891657638,
      "grad_norm": 1.6198927164077759,
      "learning_rate": 2.579902491874323e-06,
      "loss": 0.5564,
      "step": 7010
    },
    {
      "epoch": 1.9014084507042255,
      "grad_norm": 0.8842129707336426,
      "learning_rate": 2.5121885157096427e-06,
      "loss": 0.5845,
      "step": 7020
    },
    {
      "epoch": 1.9041170097508124,
      "grad_norm": 1.1034159660339355,
      "learning_rate": 2.444474539544962e-06,
      "loss": 0.6146,
      "step": 7030
    },
    {
      "epoch": 1.9068255687973998,
      "grad_norm": 0.9795628190040588,
      "learning_rate": 2.376760563380282e-06,
      "loss": 0.5056,
      "step": 7040
    },
    {
      "epoch": 1.909534127843987,
      "grad_norm": 1.0065391063690186,
      "learning_rate": 2.309046587215601e-06,
      "loss": 0.6643,
      "step": 7050
    },
    {
      "epoch": 1.9122426868905742,
      "grad_norm": 1.3199918270111084,
      "learning_rate": 2.241332611050921e-06,
      "loss": 0.6134,
      "step": 7060
    },
    {
      "epoch": 1.9149512459371616,
      "grad_norm": 0.6417984962463379,
      "learning_rate": 2.1736186348862407e-06,
      "loss": 0.4585,
      "step": 7070
    },
    {
      "epoch": 1.9176598049837486,
      "grad_norm": 1.0211318731307983,
      "learning_rate": 2.10590465872156e-06,
      "loss": 0.5503,
      "step": 7080
    },
    {
      "epoch": 1.920368364030336,
      "grad_norm": 1.0223242044448853,
      "learning_rate": 2.03819068255688e-06,
      "loss": 0.704,
      "step": 7090
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 1.2692968845367432,
      "learning_rate": 1.9704767063921996e-06,
      "loss": 0.6759,
      "step": 7100
    },
    {
      "epoch": 1.9257854821235103,
      "grad_norm": 1.099442958831787,
      "learning_rate": 1.9027627302275191e-06,
      "loss": 0.5247,
      "step": 7110
    },
    {
      "epoch": 1.9284940411700975,
      "grad_norm": 0.8611810803413391,
      "learning_rate": 1.8350487540628385e-06,
      "loss": 0.5591,
      "step": 7120
    },
    {
      "epoch": 1.9312026002166847,
      "grad_norm": 1.2743576765060425,
      "learning_rate": 1.7673347778981584e-06,
      "loss": 0.609,
      "step": 7130
    },
    {
      "epoch": 1.933911159263272,
      "grad_norm": 0.9782966375350952,
      "learning_rate": 1.699620801733478e-06,
      "loss": 0.5644,
      "step": 7140
    },
    {
      "epoch": 1.936619718309859,
      "grad_norm": 1.3063716888427734,
      "learning_rate": 1.6319068255687973e-06,
      "loss": 0.6337,
      "step": 7150
    },
    {
      "epoch": 1.9393282773564464,
      "grad_norm": 1.0561178922653198,
      "learning_rate": 1.5641928494041169e-06,
      "loss": 0.6634,
      "step": 7160
    },
    {
      "epoch": 1.9420368364030336,
      "grad_norm": 1.1717119216918945,
      "learning_rate": 1.4964788732394366e-06,
      "loss": 0.6761,
      "step": 7170
    },
    {
      "epoch": 1.9447453954496208,
      "grad_norm": 1.1137702465057373,
      "learning_rate": 1.4287648970747564e-06,
      "loss": 0.5909,
      "step": 7180
    },
    {
      "epoch": 1.9474539544962082,
      "grad_norm": 0.9736832976341248,
      "learning_rate": 1.361050920910076e-06,
      "loss": 0.5732,
      "step": 7190
    },
    {
      "epoch": 1.9501625135427951,
      "grad_norm": 1.0812307596206665,
      "learning_rate": 1.2933369447453955e-06,
      "loss": 0.5378,
      "step": 7200
    },
    {
      "epoch": 1.9528710725893825,
      "grad_norm": 1.2014563083648682,
      "learning_rate": 1.2256229685807153e-06,
      "loss": 0.4675,
      "step": 7210
    },
    {
      "epoch": 1.9555796316359697,
      "grad_norm": 1.1149441003799438,
      "learning_rate": 1.1579089924160346e-06,
      "loss": 0.63,
      "step": 7220
    },
    {
      "epoch": 1.9582881906825569,
      "grad_norm": 1.2334383726119995,
      "learning_rate": 1.0901950162513544e-06,
      "loss": 0.5937,
      "step": 7230
    },
    {
      "epoch": 1.960996749729144,
      "grad_norm": 1.0325921773910522,
      "learning_rate": 1.022481040086674e-06,
      "loss": 0.5406,
      "step": 7240
    },
    {
      "epoch": 1.9637053087757312,
      "grad_norm": 1.1845060586929321,
      "learning_rate": 9.547670639219935e-07,
      "loss": 0.5376,
      "step": 7250
    },
    {
      "epoch": 1.9664138678223186,
      "grad_norm": 1.0834722518920898,
      "learning_rate": 8.870530877573132e-07,
      "loss": 0.6287,
      "step": 7260
    },
    {
      "epoch": 1.9691224268689056,
      "grad_norm": 0.9185779690742493,
      "learning_rate": 8.193391115926328e-07,
      "loss": 0.512,
      "step": 7270
    },
    {
      "epoch": 1.971830985915493,
      "grad_norm": 1.5999085903167725,
      "learning_rate": 7.516251354279523e-07,
      "loss": 0.5406,
      "step": 7280
    },
    {
      "epoch": 1.9745395449620802,
      "grad_norm": 1.245146632194519,
      "learning_rate": 6.83911159263272e-07,
      "loss": 0.754,
      "step": 7290
    },
    {
      "epoch": 1.9772481040086674,
      "grad_norm": 1.122765302658081,
      "learning_rate": 6.161971830985915e-07,
      "loss": 0.6161,
      "step": 7300
    }
  ],
  "logging_steps": 10,
  "max_steps": 7384,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.292929368378573e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
